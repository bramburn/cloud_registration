# Detailed Backlog: Sprint 6, Sub-Sprint 6.4 - End-to-End Test & Workflow Integration

## Introduction

This document provides a detailed backlog for Sub-Sprint 6.4: End-to-End
Test & Workflow Integration. This sub-sprint is dedicated to creating a
comprehensive automated integration test for the entire quality
reporting workflow (deviation map, quality assessment, and PDF report
generation). This test will validate the seamless integration of all
components developed in Sprint 6, ensuring the robust delivery of
quality assessment features towards the Minimum Competitive Product
(MCP).

## User Stories

- **User Story 1**: As a developer, I want a comprehensive automated
  end-to-end test for the quality reporting workflow.

  - **Description**: This user story aims to create a single, automated
    test that simulates the full user journey through quality assessment
    features. This includes: loading scans, performing a registration,
    enabling/disabling the deviation map, triggering a quality
    assessment, and generating a PDF report with custom options. It will
    verify that all backend logic, frontend interactions (mocked), and
    data flows are correct and stable.

  - **Actions to Undertake**:

    1.  **Create New Test File**: Create a new C++ test file:
        tests/integration/quality_reporting_e2e_test.cpp.

    2.  **Setup Test Fixture**: Define a Google Test fixture
        (QualityReportingE2ETest) that sets up and tears down all
        necessary components and mocks.

    3.  **Instantiate Core Components**:

        - std::unique_ptr\<MainPresenter\> m_presenter;

        - std::unique_ptr\<RegistrationProject\> m_registrationProject;

        - std::unique_ptr\<AlignmentEngine\> m_alignmentEngine;

        - std::unique_ptr\<QualityAssessment\> m_qualityAssessment;

        - std::unique_ptr\<PDFReportGenerator\> m_pdfReportGenerator;

        - std::unique_ptr\<PointCloudLoadManager\> m_loadManager;

        - std::unique_ptr\<ProjectManager\> m_projectManager;

        - std::unique_ptr\<Analysis::DifferenceAnalysis\>
          m_differenceAnalysis; (if mocked separately from
          AlignmentEngine).

    4.  **Instantiate Mock Components**:

        - std::unique_ptr\<NiceMock\<MockMainView\>\> m_mockView;

        - std::unique_ptr\<NiceMock\<MockE57Parser\>\> m_mockParser;

        - std::unique_ptr\<NiceMock\<MockPointCloudViewer\>\>
          m_mockViewer; (obtained from m_mockView-\>getMockViewer()).

        - std::unique_ptr\<NiceMock\<MockReportOptionsDialog\>\>
          m_mockReportOptionsDialog; (new mock for S6.3 dialog).

    5.  **Inject Dependencies**: Initialize m_presenter with raw
        pointers to mock interfaces and concrete core components.

    6.  **Mock Setup - Initial State and Behaviors**:

        - Configure m_mockView for all UI interactions (file dialogs,
          messages, action enablement, progress).

        - Configure m_mockParser for successful scan loading.

        - Configure m_mockViewer for loadPointCloud(),
          loadColorizedPointCloud(), revertToOriginalColors(),
          setDeviationMapLegendVisible().

        - Configure m_mockReportOptionsDialog to return
          QDialog::Accepted and a predefined ReportOptions struct, and
          to emit progress/completion signals.

        - Configure m_qualityAssessment to emit assessmentCompleted with
          a valid QualityReport.

        - Configure m_pdfReportGenerator to emit reportGenerated on
          generatePdfReport().

        - Set up initial RegistrationProject state to contain two loaded
          scans and an accepted RegistrationResult.

    7.  **Simulate Workflow Steps**:

        - **Project Initialization**: Call
          m_presenter-\>handleNewProject().

        - **Load and Register Scans**: Simulate loading scan_A.e57 and
          scan_B.e57. Programmatically set up an accepted
          RegistrationResult in m_registrationProject (since prior
          registration is a prerequisite).

        - **Trigger Quality Assessment**: Call
          m_presenter-\>handleQualityAssessmentClicked(). Verify
          m_qualityAssessment-\>assessRegistrationQuality() is called
          and m_presenter-\>onQualityAssessmentCompleted() is triggered.

        - **Toggle Deviation Map ON**: Call
          m_presenter-\>handleShowDeviationMapToggled(true). Verify
          m_alignmentEngine-\>analyzeDeviation() and
          m_mockViewer-\>loadColorizedPointCloud().

        - **Toggle Deviation Map OFF**: Call
          m_presenter-\>handleShowDeviationMapToggled(false). Verify
          m_mockViewer-\>revertToOriginalColors().

        - **Generate Report**: Call
          m_presenter-\>handleGenerateReportClicked(). Verify
          m_mockReportOptionsDialog is launched. Simulate dialog
          acceptance. Verify m_pdfReportGenerator-\>generatePdfReport()
          is called.

    8.  **Verify Final State**: Assert that internal states
        (RegistrationProject, MainPresenter) are correct, and all mock
        expectations are met. Check logs for any unexpected
        warnings/errors.

  - **References between Files**: This test will integrate and verify
    components across src/app/, src/registration/, src/analysis/,
    src/export/, src/quality/, and their corresponding tests/mocks/
    interfaces.

  - **List of Files being Created**:

    - tests/integration/quality_reporting_e2e_test.cpp: The main test
      file for this sub-sprint.

    - tests/mocks/MockReportOptionsDialog.h: A mock for the
      ReportOptionsDialog to control its behavior in tests.

  - **Acceptance Criteria**:

    - A new automated test file
      tests/integration/quality_reporting_e2e_test.cpp exists and is
      correctly configured in CMake.

    - A MockReportOptionsDialog class is created to facilitate testing
      the UI interaction.

    - The test compiles and executes successfully without errors or
      crashes.

    - The test comprehensively simulates the entire quality reporting
      workflow: triggering assessment, enabling/disabling deviation map,
      and generating a PDF report.

    - All key interactions between MainPresenter, IMainView (mocked),
      IPointCloudViewer (mocked), AlignmentEngine, QualityAssessment,
      PDFReportGenerator, ReportOptionsDialog (mocked), and
      DifferenceAnalysis (via AlignmentEngine) are verified through mock
      expectations.

    - The test confirms that data (e.g., QualityReport, colorized
      points) flows correctly through the system.

  - **Testing Plan**:

    - **Test Case 1**: Full Quality Reporting Workflow Simulation.

      - **Test Data**:

        - Mocked point cloud data for two scans (scan_A, scan_B).

        - Predefined RegistrationResult in RegistrationProject
          (simulating a prior accepted alignment) that would yield a
          specific QualityReport.

        - Specific ReportOptions to be returned by
          MockReportOptionsDialog.

      - **Expected Result**:

        - All EXPECT_CALLs on mocks are satisfied.

        - m_presenter-\>m_lastQualityReport is updated.

        - m_mockViewer is called with loadColorizedPointCloud() and
          revertToOriginalColors().

        - m_pdfReportGenerator is called with the correct QualityReport
          and ReportOptions.

        - No error messages are displayed.

        - The test completes within a reasonable time frame.

      - **Testing Tool**: Google Test / Google Mock.

## Actions to Undertake (Consolidated)

1.  **New File Creation**:

    - tests/integration/quality_reporting_e2e_test.cpp

    - tests/mocks/MockReportOptionsDialog.h

2.  **Test File Setup**:

    - **tests/integration/quality_reporting_e2e_test.cpp**:

      - Define QualityReportingE2ETest fixture.

      - Instantiate MainPresenter, RegistrationProject, AlignmentEngine,
        QualityAssessment, PDFReportGenerator, PointCloudLoadManager,
        ProjectManager, and DifferenceAnalysis (if not part of
        AlignmentEngine).

      - Instantiate NiceMock\<MockMainView\>, NiceMock\<MockE57Parser\>,
        NiceMock\<MockPointCloudViewer\>,
        NiceMock\<MockReportOptionsDialog\>.

      - In SetUp(): Inject dependencies into MainPresenter.

      - Set up ON_CALL expectations for all mocks to simulate successful
        operations and data returns.

      - Crucially, m_registrationProject needs to be pre-populated with
        a RegistrationResult to simulate a completed alignment.

      - m_qualityAssessment needs to be configured to emit a specific
        QualityReport.

      - m_pdfReportGenerator needs to be configured to emit
        reportGenerated.

3.  **Mock Implementation**:

    - **tests/mocks/MockReportOptionsDialog.h**:

      - Define a mock class MockReportOptionsDialog that inherits from
        ReportOptionsDialog.

      - Mock its constructor, exec(), getReportOptions(),
        setReportOptions(), onReportProgress(), onReportFinished(), and
        signals (generateReportRequested).

      - Implement exec() to return QDialog::Accepted and
        generateReportRequested signal.

4.  **Test Case Implementation**:

    - In tests/integration/quality_reporting_e2e_test.cpp:

      - Implement TEST_F(QualityReportingE2ETest,
        FullQualityReportingWorkflow).

      - **Simulate Load & Registration Prerequisites**:

        - Use m_projectManager to create a project.

        - Use m_loadManager and m_mockParser to simulate loading two
          scans (scan_A, scan_B).

        - Manually add a RegistrationResult to m_registrationProject for
          scan_A and scan_B with a predefined transformation (to
          simulate an already accepted alignment).

      - **Trigger Quality Assessment**:

        - Call m_presenter-\>handleQualityAssessmentClicked().

        - Verify EXPECT_CALL(\*m_qualityAssessment,
          assessRegistrationQuality(\...)).

        - Manually trigger
          m_presenter-\>onQualityAssessmentCompleted(mockQualityReport);

      - **Toggle Deviation Map**:

        - EXPECT_CALL(\*m_mockViewer,
          loadColorizedPointCloud(testing::\_));

        - EXPECT_CALL(\*m_mockViewer, setDeviationMapLegendVisible(true,
          testing::\_));

        - m_presenter-\>handleShowDeviationMapToggled(true);

        - EXPECT_CALL(\*m_mockViewer, revertToOriginalColors());

        - EXPECT_CALL(\*m_mockViewer,
          setDeviationMapLegendVisible(false, testing::\_));

        - m_presenter-\>handleShowDeviationMapToggled(false);

      - **Generate Report**:

        - EXPECT_CALL(\*m_mockView, askForSaveFilePath(testing::\_,
          testing::\_)).WillOnce(testing::Return(\"mock_report.pdf\"));

        - EXPECT_CALL(\*m_mockReportOptionsDialog,
          exec()).WillOnce(testing::Return(QDialog::Accepted));

        - EXPECT_CALL(\*m_mockReportOptionsDialog,
          getReportOptions()).WillOnce(testing::Return(testReportOptions));

        - EXPECT_CALL(\*m_pdfReportGenerator,
          generatePdfReport(testing::\_,
          testing::\_)).WillOnce(testing::DoAll(testing::InvokeWithoutArgs(\[&\](){
          m_pdfReportGenerator-\>reportGenerated(\"mock_report.pdf\");
          }), testing::Return()));

        - m_presenter-\>handleGenerateReportClicked();

        - Verify m_mockView\'s display messages for success.

## References between Files (Consolidated)

- **Test File**: tests/integration/quality_reporting_e2e_test.cpp

- **Mocks**: MockMainView, MockE57Parser, MockPointCloudViewer,
  MockReportOptionsDialog (new).

- **Core Components**: MainPresenter, RegistrationProject,
  AlignmentEngine, QualityAssessment, PDFReportGenerator,
  PointCloudLoadManager, ProjectManager, DifferenceAnalysis.

- **Data Structures**: QualityReport, RegistrationResult, ReportOptions,
  PointFullData.

## List of Files being Created

- **File 1**: tests/integration/quality_reporting_e2e_test.cpp

  - **Purpose**: Automated end-to-end integration test for the quality
    reporting workflow.

  - **Contents**: C++ code defining a Google Test fixture and a single
    test case that simulates the complete user journey for quality
    assessment and reporting, using mocked UI and external services,
    while interacting directly with core backend components.

  - **Relationships**: Tests the integration of components from Sprints
    3 and 6, using various mocks.

- **File 2**: tests/mocks/MockReportOptionsDialog.h

  - **Purpose**: Mock interface for the ReportOptionsDialog to control
    its behavior in integration tests.

  - **Contents**: Google Mock class definition inheriting from
    ReportOptionsDialog, with MOCK_METHODs for all virtual methods and
    signals.

  - **Relationships**: Used by
    tests/integration/quality_reporting_e2e_test.cpp.

## Acceptance Criteria (Consolidated)

- The quality_reporting_e2e_test.cpp file exists and is correctly
  configured in CMake.

- The MockReportOptionsDialog.h file exists and provides a functional
  mock for the dialog.

- The automated test successfully compiles and runs without errors or
  crashes.

- The test comprehensively simulates the entire quality reporting
  workflow:

  - Loading and (pre-configured) registering two scans.

  - Triggering a quality assessment.

  - Toggling the deviation map on and off.

  - Launching the report options dialog.

  - Generating a PDF report with specified options.

- All mock expectations are satisfied, confirming correct interaction
  patterns between components.

- The test confirms that data flows correctly through the system (e.g.,
  QualityReport generated and passed to PDFReportGenerator).

## Testing Plan (Consolidated)

- **Primary Test**: The quality_reporting_e2e_test.cpp itself.

  - **Test Data**: Synthetic in-memory point cloud data and pre-defined
    transformation for RegistrationResult. A QualityReport object with
    known metrics. ReportOptions with various flags for content.

  - **Expected Result**: All assertions within the TEST_F block pass,
    and the test run reports 1 successful test. No unexpected
    warnings/errors are logged.

  - **Testing Tool**: Google Test / Google Mock.

- **Secondary Test (Manual QA)**:

  - **Test Case**: Manual Walkthrough of Quality Reporting.

    - **Test Data**: Actual E57/LAS files.

    - **Expected Result**: Launch the full application. Load and align
      two scans. Trigger quality assessment. Enable/disable deviation
      map (verify visual). Generate a PDF report with custom options
      (verify content externally).

    - **Testing Tool**: Manual QA.

## Assumptions and Dependencies

- **Prior Sprint Completion**: All functionality from Sprints 1-5, and
  Sub-Sprints 6.1, 6.2, 6.3 are assumed to be fully implemented and
  stable. This includes:

  - Working registration workflows (manual, ICP, target-based).

  - QualityAssessment can generate a QualityReport.

  - AlignmentEngine::analyzeDeviation() can produce colorized points.

  - PDFReportGenerator can generate PDFs with options.

  - ReportOptionsDialog can capture user preferences.

- **Mock Functionality**: The provided mocks (especially
  MockReportOptionsDialog) accurately simulate the behavior of their
  real counterparts for testing.

- **Test Environment**: CMake is correctly configured for integration
  tests and linking Google Test/Mock.

- **Non-Blocking Operations**: Assumed that PDFReportGenerator and
  AlignmentEngine::analyzeDeviation() can be configured to run in the
  same thread for simpler testing, or their asynchronous nature is
  handled by the mocks.

## Non-Functional Requirements

- **Test Coverage**: This sub-sprint provides critical end-to-end test
  coverage for the quality reporting features.

- **Reliability**: The automated test provides high confidence in the
  stability of the integrated quality reporting workflow.

- **Maintainability**: The test is structured to be easily extendable as
  more quality reporting features are added.

- **Performance (of test)**: The automated test should execute quickly,
  as it relies on mocks to avoid heavy I/O or rendering.

## Conclusion

Sub-Sprint 6.4 is the final quality gate for the comprehensive quality
reporting features. By implementing a robust end-to-end integration
test, it ensures that deviation mapping and PDF report generation are
seamlessly integrated, reliable, and contribute effectively to the
Minimum Competitive Product.
