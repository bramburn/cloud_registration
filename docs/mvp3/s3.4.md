# Detailed Backlog: Sprint 3, Sub-Sprint 3.4 - End-to-End Integration Test for MVP

## Introduction

This document provides a detailed backlog for Sub-Sprint 3.4: End-to-End
Integration Test for MVP. This sub-sprint is entirely focused on quality
assurance, creating a comprehensive automated test that validates the
entire manual alignment MVP workflow. This critical test ensures that
all components developed in Sprints 1, 2, and 3 integrate seamlessly and
the core value proposition of the application is delivered reliably.

## User Stories

- **User Story 1**: As a developer, I want a single, automated
  end-to-end test for the manual alignment MVP.

  - **Description**: This test will simulate a typical user workflow for
    manual point cloud registration, from loading initial scans to
    exporting the final aligned result. It will verify that all backend
    logic, frontend interactions (mocked), and data flows are correct,
    ensuring the MVP is fully functional and stable.

  - **Actions to Undertake**:

    1.  **Create New Test File**: Create a new C++ test file:
        tests/integration/manual_alignment_e2e_test.cpp.

    2.  **Setup Test Fixture**: Define a Google Test fixture
        (ManualAlignmentE2ETest) that handles the setup and teardown of
        all necessary components and mocks.

    3.  **Instantiate Core Components**:

        - std::unique_ptr\<MainPresenter\> m_presenter;

        - std::unique_ptr\<RegistrationProject\> m_registrationProject;

        - std::unique_ptr\<AlignmentEngine\> m_alignmentEngine;

        - std::unique_ptr\<TargetManager\> m_targetManager;

        - std::unique_ptr\<NaturalPointSelector\>
          m_naturalPointSelector;

        - std::unique_ptr\<SphereDetector\> m_sphereDetector;

        - std::unique_ptr\<PointCloudLoadManager\> m_loadManager;

        - std::unique_ptr\<ProjectManager\> m_projectManager;

    4.  **Instantiate Mock Components**:

        - std::unique_ptr\<NiceMock\<MockMainView\>\> m_mockView;

        - std::unique_ptr\<NiceMock\<MockE57Parser\>\> m_mockParser;

        - std::unique_ptr\<NiceMock\<MockE57Writer\>\> m_mockWriter;

        - std::unique_ptr\<NiceMock\<MockPointCloudViewer\>\>
          m_mockViewer; (obtained from m_mockView-\>getMockViewer()).

    5.  **Inject Dependencies**: Initialize m_presenter with raw
        pointers to the mock IMainView, IE57Parser, IE57Writer. Set
        other managers (m_projectManager, m_loadManager) to m_presenter.

    6.  **Mock Setup - Initial State**:

        - m_mockView: Configure askForOpenFilePath(),
          askForConfirmation(), displayErrorMessage(),
          displayInfoMessage(), updateStatusBar(), setWindowTitle(),
          setActionsEnabled(), showProgressDialog(), updateProgress().

        - m_mockParser: Configure openFile(), extractPointData(),
          getPointCount(), isValidE57File() for successful loading of
          two distinct scans.

        - m_mockViewer: Configure loadPointCloud(),
          clearDynamicTransform(), resetCamera(), hasPointCloudData().

        - m_mockWriter: Configure createFile(), writePoints(),
          closeFile() for successful export.

        - m_projectManager: Mock createProject(), loadProject(),
          setScanTransform(), addScan(), removeScan().

        - m_loadManager: Mock loadScan(), unloadScan(),
          getLoadedPointFullData().

    7.  **Simulate Workflow Steps**:

        - **Project Creation**: Call m_presenter-\>handleNewProject().
          Mock file dialog and project manager responses.

        - **Load Scan A**: Simulate user selecting scan_A.e57. Call
          m_presenter-\>handleImportScans(). Mock parser to return data
          for scan_A. Verify m_viewer-\>loadPointCloud() is called for
          scan_A.

        - **Load Scan B**: Simulate user selecting scan_B.e57. Call
          m_presenter-\>handleImportScans(). Mock parser to return data
          for scan_B. Verify m_viewer-\>loadPointCloud() is called for
          scan_B.

        - **Manual Alignment (Point Selection)**:

          - Simulate entering manual alignment mode.

          - Directly call
            m_alignmentEngine-\>addCorrespondence(QVector3D, QVector3D)
            for multiple (at least 3) pairs. Ensure TargetManager
            correctly stores them.

        - **Compute Alignment**: Call
          m_alignmentEngine-\>recomputeAlignment(). Verify
          m_viewer-\>setDynamicTransform() is called.

        - **Accept Alignment**: Call
          m_presenter-\>handleAcceptAlignment(). Verify
          m_viewer-\>clearDynamicTransform(),
          m_registrationProject-\>setScanTransform(), and
          m_registrationProject-\>addRegistrationResult() are called.

        - **Export**: Call m_presenter-\>handleExportPointCloud(). Mock
          save file dialog. Verify m_viewer-\>getCurrentPointCloudData()
          is called (to get transformed data). Verify
          m_mockWriter-\>createFile(), writePoints(), closeFile() are
          called.

    8.  **Verify Final State**: Assert that the state of
        m_registrationProject (scan transforms, saved results),
        m_presenter (file open status), and mock call counts are as
        expected.

  - **References between Files**: This test will implicitly involve
    almost all files modified in Sprints 1, 2, and 3, using their mocked
    or concrete implementations.

  - **List of Files being Created**:

    - tests/integration/manual_alignment_e2e_test.cpp: The main test
      file for this sub-sprint.

  - **Acceptance Criteria**:

    - A new automated test file
      tests/integration/manual_alignment_e2e_test.cpp exists.

    - The test compiles and executes successfully without errors or
      crashes.

    - The test covers all critical steps of the manual alignment MVP
      workflow: project creation, loading two scans, selecting points,
      computing alignment, accepting the alignment, and exporting the
      final result.

    - All key interactions between the MainPresenter, IMainView
      (mocked), IE57Parser (mocked), IPointCloudViewer (mocked),
      AlignmentEngine, RegistrationProject, TargetManager, and
      PointCloudExporter (mocked) are verified through mock
      expectations.

    - The test confirms that data flows correctly through the system and
      that transformations are applied and persisted.

  - **Testing Plan**:

    - **Test Case 1**: Full MVP Manual Alignment Workflow Simulation.

      - **Test Data**:

        - Mocked E57 files to return predefined std::vector\<float\>
          data for two distinct scans (e.g., one slightly
          translated/rotated from the other).

        - Predefined QVector3D pairs for manual alignment (input to
          addCorrespondence()) that would result in a known
          transformation.

        - A mock export file path.

      - **Expected Result**:

        - All EXPECT_CALLs on mocks are satisfied.

        - MainPresenter\'s internal state (e.g., isFileOpen,
          isProjectOpen) reflects completion of each step.

        - RegistrationProject contains updated scan transformations and
          a RegistrationResult entry.

        - No error messages are displayed.

        - The test completes within a reasonable time frame (e.g., under
          5-10 seconds, as no actual file I/O or rendering is
          performed).

      - **Testing Tool**: Google Test / Google Mock.

## Actions to Undertake (Consolidated)

1.  **Test File Creation**:

    - Create tests/integration/manual_alignment_e2e_test.cpp.

    - Add this executable to the tests/CMakeLists.txt file and include
      it in the ALL_TESTS variable (or a new INTEGRATION_TESTS
      variable).

2.  **Test Fixture Definition**:

    - Define a Google Test fixture class (ManualAlignmentE2ETest) in
      manual_alignment_e2e_test.cpp.

    - In SetUp(): Instantiate all necessary std::unique_ptrs for
      concrete core components (RegistrationProject, AlignmentEngine,
      TargetManager, NaturalPointSelector, SphereDetector,
      PointCloudLoadManager, ProjectManager) and NiceMock instances for
      interfaces (MockMainView, MockE57Parser, MockE57Writer).

    - In SetUp(): Perform dependency injection for the MainPresenter,
      connecting it to the mock interfaces and real core components.

    - In TearDown(): Ensure proper cleanup (though std::unique_ptr helps
      with this).

3.  **Mock Configuration**:

    - Within the ManualAlignmentE2ETest fixture\'s SetUp() method, or in
      helper methods, configure the ON_CALL expectations for all mock
      objects.

    - Define the test data (e.g., std::vector\<float\> for scan content,
      QVector3D for manual alignment points).

    - Simulate successful file dialogs, parser operations, viewer
      interactions, and writer operations.

4.  **Test Case Implementation**:

    - Implement the TEST_F(ManualAlignmentE2ETest,
      FullManualAlignmentWorkflow) test case.

    - Implement the sequence of calls to m_presenter methods that
      simulate user actions (e.g., handleNewProject(),
      handleImportScans(), handlePointSelected(),
      handleAcceptAlignment(), handleExportPointCloud()).

    - Use EXPECT_CALL and ASSERT_TRUE/EXPECT_TRUE extensively to verify
      correct interactions, state changes, and data integrity throughout
      the workflow.

    - Use testing::DoAll, testing::Return, testing::Invoke for complex
      mock behaviors (e.g., Invoke a lambda to trigger signals from
      mocked parsers).

    - For handlePointSelected(), since it\'s triggered by
      PointCloudViewerWidget, the test would directly call
      m_presenter-\>handlePointSelected(\...) to simulate the viewer\'s
      signal. For the points themselves, directly call
      m_alignmentEngine-\>addCorrespondence(\...) to simulate user
      picking for simplicity, rather than simulating mouse events.

## References between Files (Consolidated)

- **Test File**: tests/integration/manual_alignment_e2e_test.cpp

- **Core Components (concrete implementation)**:

  - src/registration/RegistrationProject.h / RegistrationProject.cpp

  - src/registration/AlignmentEngine.h / AlignmentEngine.cpp

  - src/registration/TargetManager.h / TargetManager.cpp

  - src/registration/NaturalPointSelector.h / NaturalPointSelector.cpp

  - src/registration/SphereDetector.h / SphereDetector.cpp (though not
    directly used for manual alignment, part of detection module)

  - src/app/MainPresenter.h / MainPresenter.cpp

  - src/core/projectmanager.h / projectmanager.cpp

  - src/app/pointcloudloadmanager.h / pointcloudloadmanager.cpp

- **Mock Interfaces**:

  - tests/mocks/MockMainView.h (implements IMainView)

  - tests/mocks/MockE57Parser.h (implements IE57Parser)

  - tests/mocks/MockE57Writer.h (implements IE57Writer)

  - tests/mocks/MockPointCloudViewer.h (implements IPointCloudViewer,
    obtained from MockMainView)

- **Data Structures**:

  - export/IFormatWriter.h (for Point struct)

  - registration/TargetCorrespondence.h

  - registration/RegistrationProject.h (for RegistrationResult struct)

## List of Files being Created

- **File 1**: tests/integration/manual_alignment_e2e_test.cpp

  - **Purpose**: Automated end-to-end integration test for the core
    manual alignment workflow (MVP).

  - **Contents**: C++ code defining a Google Test fixture and a single
    test case that simulates the complete user journey using mocked UI
    and external services, while interacting directly with the
    MainPresenter and core backend components. It will include
    comprehensive mock expectations and assertions.

  - **Relationships**: This file tests the integration of nearly all
    components from Sprints 1, 2, and 3. It depends on Google Test/Mock,
    and the mock interface headers.

## Acceptance Criteria (Consolidated)

- The manual_alignment_e2e_test.cpp file exists and is correctly
  configured in CMake.

- The automated test successfully runs to completion without errors or
  crashes.

- The test verifies that a new project can be created.

- The test verifies that two scans can be loaded into the viewer.

- The test verifies that manual point correspondences can be added and
  trigger alignment computation/preview.

- The test verifies that the computed alignment can be successfully
  accepted, leading to permanent changes in the RegistrationProject.

- The test verifies that the aligned point cloud can be successfully
  exported.

- All mock expectations within the test are satisfied, confirming
  correct interaction patterns between components.

## Testing Plan (Consolidated)

- **Primary Test**: The manual_alignment_e2e_test.cpp itself.

  - **Test Data**: Synthetic in-memory point cloud data generated by
    mocks for scans. Predefined QVector3D pairs for manual point picking
    to simulate a simple, known transformation. Mocked file paths for
    project and export.

  - **Expected Result**: All assertions within the TEST_F block pass,
    and the test run reports 1 successful test. No qWarning() or
    qCritical() messages related to logical errors or unexpected
    behavior are logged during execution.

  - **Testing Tool**: Google Test / Google Mock (run via CTest or
    directly).

- **Secondary Test (Manual QA)**:

  - **Test Case**: Manual Walkthrough of MVP Workflow.

    - **Test Data**: Actual E57/LAS files (e.g., bunnyDouble.e57,
      bunnyInt32.e57).

    - **Expected Result**: Launch the full application. Perform all
      steps of the MVP workflow manually: create project, import two
      scans, manually select points, compute alignment, accept, and
      export to a file. Verify visual correctness at each step (viewer
      preview, status messages, tree view grouping). Verify the exported
      file externally.

    - **Testing Tool**: Manual QA.

## Assumptions and Dependencies

- **All Prior Sub-Sprints Completed**: All functionality outlined in
  Sub-Sprints 1.1, 1.2, 1.3, 2.1, 2.2, 2.3, 3.1, 3.2, and 3.3 is assumed
  to be fully implemented and stable. This includes:

  - Manual point selection logic.

  - AlignmentEngine for computation and state management.

  - LeastSquaresAlignment for core transformation.

  - ErrorAnalysis for metrics.

  - RegistrationProject for persistent data (scan transforms, results).

  - PointCloudViewerWidget for 3D visualization and dynamic transforms.

  - ExportDialog and PointCloudExporter for file export.

  - ProjectTreeModel and SidebarWidget for scan grouping.

- **Mock Functionality**: The provided mock classes (MockMainView,
  MockE57Parser, MockE57Writer, MockPointCloudViewer) are fully
  functional and accurately simulate the behavior of their real
  counterparts for testing purposes.

- **Build System**: CMake is correctly configured to find and link
  Google Test/Mock.

- **Test Data Availability**: The test can rely on generating synthetic
  in-memory data for point clouds, avoiding external file dependencies
  where possible in unit tests.

## Non-Functional Requirements

- **Test Coverage**: This sub-sprint ensures high-level end-to-end test
  coverage for the MVP.

- **Reliability**: The automated test provides a high degree of
  confidence in the overall system\'s reliability and stability.

- **Maintainability**: The test should be well-structured and easy to
  understand, allowing for future extensions and debugging.

- **Performance (of test)**: The automated test should execute quickly
  (within seconds), as it relies heavily on mocks.

## Conclusion

Sub-Sprint 3.4 is the final validation gate for the MVP. By creating a
robust end-to-end integration test, the project ensures that its core
manual alignment functionality is production-ready, setting a strong
foundation for future feature development and the pursuit of the Minimum
Competitive Product.
