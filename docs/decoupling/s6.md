Project Backlog: Core Component Decoupling - Sprint 6
Introduction

This document provides a detailed backlog for Sprint 6 of the Core Component Decoupling initiative. With the foundational refactoring to a Model-View-Presenter (MVP) architecture complete, this sprint aims to capitalize on the improved modularity and maintainability of the codebase. The focus will be on two key areas: implementing advanced performance optimizations for the rendering pipeline and introducing a significant new featureâ€”the ability to visualize multiple point cloud scans simultaneously.
User Stories
User Story 1: Advanced Rendering Performance Optimization

    Description: As a C++ developer, I want to optimize the point cloud rendering pipeline by implementing more advanced techniques, such as GPU-based culling. This will enable the application to handle significantly larger datasets at interactive frame rates, pushing the boundaries of its performance capabilities.

    Actions to Undertake:

        Research GPU Culling Techniques: Investigate modern GPU-based culling methods suitable for point cloud data, such as compute-shader-based frustum and occlusion culling.

        Implement a GpuCuller Module: Create a new, dedicated module responsible for performing culling operations on the GPU. This module will take the camera's view frustum and a list of point cloud nodes as input and output a list of visible nodes.

        Integrate GpuCuller into Rendering Loop: Modify the PointCloudViewerWidget to use the new GpuCuller module. The rendering loop will now first dispatch a compute shader to determine visible nodes and then use the result to draw only the necessary data.

        Profile and Benchmark: Conduct detailed performance profiling of the new rendering pipeline. Compare its performance with the previous CPU-based culling to quantify the improvement.

    References between Files:

        pointcloudviewerwidget.cpp will #include "GpuCuller.h" and will use it to determine which parts of the octree to render.

        The GpuCuller will require access to the octree data structure and will likely need its own GLSL compute shader files.

    Acceptance Criteria:

        The application can render a dataset of at least 50 million points at a minimum of 30 frames per second (FPS).

        The new GpuCuller module is fully unit-tested.

        A performance analysis report shows a measurable improvement (at least a 50% increase in FPS for large datasets) compared to the previous rendering implementation.

    Testing Plan:

        Unit tests for the GpuCuller module will verify the correctness of the culling logic.

        Performance benchmark tests will be run on various large datasets to measure the FPS improvement.

        Manual visual testing will ensure that the rendering output is correct and that no visual artifacts are introduced.

User Story 2: Multi-Scan Visualization

    Description: As a user (e.g., a surveyor or engineer), I want to load and view multiple point cloud scans simultaneously in the 3D viewer. This will allow me to compare different scans, see how they align, and get a more complete view of a combined scene.

    Actions to Undertake:

        Update Data Management Logic: Modify the PointCloudLoadManager and MainPresenter to manage a list of active/loaded scans instead of just a single one.

        Enhance PointCloudViewerWidget: Refactor the viewer to render multiple, distinct point cloud models. This will involve managing multiple vertex buffers and rendering each active scan in the scene.

        Implement Scan Differentiation: Add a mechanism to visually distinguish between the different loaded scans, such as assigning a unique color to each one.

        Update UI for Multi-Selection: Modify the SidebarWidget to allow users to select multiple scans (e.g., using checkboxes) and trigger a "Load Selected" action.

    References between Files:

        PointCloudLoadManager and MainPresenter will need to be updated to handle a collection of active scans.

        PointCloudViewerWidget will be significantly refactored to manage and render multiple point clouds.

        SidebarWidget will be updated to support multi-selection and emit a new signal, such as loadScansRequested(const QStringList& scanIds).

    Acceptance Criteria:

        A user can select multiple scans from the sidebar and load them into the viewer simultaneously.

        Each loaded scan is rendered with a distinct visual property (e.g., color) to differentiate it from the others.

        The application remains stable and responsive when multiple scans are loaded.

        Users can clear individual scans or all scans from the viewer.

    Testing Plan:

        Manual end-to-end testing will be the primary method for validating this feature. Test scenarios will include loading two or more scans, verifying their distinct appearance, and ensuring the application performs well.

        Integration tests will be written to verify that the presenter correctly handles requests to load and unload multiple scans.

List of Files being Created

    File 1: src/rendering/GpuCuller.h

        Purpose: Header file for the new GPU-based culling module.

        Contents: Class definition for GpuCuller, including methods to initialize GPU resources (e.g., compute shaders, buffers) and to execute the culling process.

        Relationships: Used by PointCloudViewerWidget.

    File 2: src/rendering/GpuCuller.cpp

        Purpose: Implementation file for the GpuCuller class.

        Contents: The logic for setting up and dispatching the compute shader, as well as for retrieving and interpreting the culling results.

        Relationships: Implements the class defined in GpuCuller.h.

    File 3: shaders/culling.comp

        Purpose: A GLSL compute shader for performing frustum and occlusion culling on the GPU.

        Contents: The shader code will take the octree structure and camera parameters as input and will output a list of visible node indices.

        Relationships: Loaded and used by the GpuCuller module.

    File 4: tests/test_gpuculler.cpp

        Purpose: Unit test file for the GpuCuller module.

        Contents: A suite of tests to verify the correctness of the GPU culling logic, likely by comparing its output to a CPU-based implementation.

        Relationships: Tests the GpuCuller class.

Acceptance Criteria

    The application can successfully render datasets of over 50 million points at interactive frame rates (30+ FPS).

    Users can select and view multiple scans at the same time, with each scan being visually distinct.

    The application remains stable and its memory usage is manageable, even with multiple large scans loaded.

    All new code is covered by automated tests, and all existing tests continue to pass.

Testing Plan

    Test Case 1: GPU Culling Performance Benchmark

        Test Data: A very large point cloud dataset (50-100 million points).

        Expected Result: The application should maintain a minimum of 30 FPS while navigating the scene. The number of rendered points should dynamically change based on the camera's position and orientation.

        Testing Tool: A custom performance benchmark script and manual testing.

    Test Case 2: Multi-Scan Visualization Test

        Test Data: At least three different point cloud files (E57 or LAS).

        Expected Result: The user can load all three scans simultaneously. Each scan should be rendered in a different color. The user can interact with the combined scene smoothly.

        Testing Tool: Manual testing.

    Test Case 3: Full Regression Suite

        Test Data: All automated tests from Sprints 1-5.

        Expected Result: All
        tests pass, ensuring that the new features and optimizations have not introduced any regressions.

        Testing Tool: GTest/GMock.

Assumptions and Dependencies

    Assumptions:

        The target hardware supports compute shaders and has sufficient VRAM to handle the GPU culling process and store multiple point clouds.

        The existing MVP architecture is flexible enough to accommodate the management of multiple active scans.

    Dependencies:

        A stable build environment with all necessary graphics drivers and libraries.

        The successful completion and integration of all refactoring work from the previous sprints.

Non-Functional Requirements

    Performance: The primary goal of this sprint is to significantly improve rendering performance for large datasets.

    Scalability: The application should be able to handle a reasonable number of simultaneously loaded scans without a critical drop in performance or stability. The definition of "reasonable" will be determined during testing but should be at least 3-5 medium-sized scans.

    Usability: The process of loading and viewing multiple scans should be intuitive and straightforward for the user.

Conclusion

Sprint 6 is focused on delivering tangible value based on the architectural improvements made in the previous sprints. By tackling advanced performance optimizations and introducing a highly requested multi-scan visualization feature, this sprint will demonstrate the real-world benefits of the refactoring effort. The successful completion of this sprint will result in a more powerful, performant, and feature-rich application.