# **Developing an Interactive 3D Point Cloud Street View in Qt6**

## **I. Executive Summary**

This report outlines a comprehensive technical strategy for integrating an interactive, Google Street View-like spherical panorama feature into an existing Qt6 application that processes point cloud data. The proposed solution is designed to enhance user experience by providing an immersive 3D visualization from any user-defined point on a scan map. It will leverage the robust 3D scene management and rendering capabilities of Qt3D, presenting a dual-panel interface reminiscent of Faro Scene’s registration view.  
Key functionalities include the precise placement of a virtual camera, automatically offset 1.6 meters from the detected floor at a user-selected pin location. From this viewpoint, a real-time 360-degree spherical view will be generated by intelligently projecting the surrounding point cloud data using advanced rendering techniques such as ray casting and cubemaps. Users will be able to interactively pan and tilt within this immersive view. Furthermore, the system will enable direct selection of features like target boards and spheres within the 3D panorama, followed by on-demand 3D measurement capabilities for distances and angles.  
A critical focus of this development is performance optimization, particularly for handling large point cloud datasets. This will involve the strategic implementation of spatial data structures, such as Octrees and K-D trees, for accelerated queries, alongside advanced Level of Detail (LOD) management techniques. The architectural design prioritizes modularity and scalability, establishing a solid foundation for future enhancements and ensuring a fluid, responsive user experience.

## **II. Project Scope and Technical Requirements**

### **A. User Story and Core Functionality**

The envisioned feature aims to transform how users interact with point cloud data by providing an intuitive, immersive visualization experience. The core functionalities are designed to mirror the familiarity of widely used geospatial tools while adapting to the unique characteristics of 3D scan data.  
The user interaction begins with **pin-dropping for virtual viewpoint placement**. Within an existing 2D representation of the scan map—likely a top-down or orthographic view of the loaded point cloud—the user will click to designate a point of interest. This selected 2D coordinate will serve as the horizontal anchor for the virtual camera's position in the 3D environment.  
Upon the pin-drop, the system will generate a **real-time 3D spherical panoramic view**. This new view will simulate a 360-degree camera perspective from the precisely determined 3D location corresponding to the pinned point. The view must dynamically render the surrounding point cloud data, creating an immersive environment akin to Google Street View.  
Once the spherical view is active, users must be able to perform **interactive panning within the spherical view**. This involves rotating the virtual camera view horizontally (yaw) and vertically (pitch) to explore the environment from the fixed pinned location. This fluid, immersive navigation is central to the user experience.  
A crucial interactive element is the **selection of features (target boards, spheres) within the view**. Within the spherical panorama, users will need the ability to click on visible point cloud features, such as predefined target boards or distinct spherical objects. This selection mechanism will enable further analysis and interaction.  
Following feature selection, the system must provide **on-demand measurement tools**. Users should be able to perform precise 3D measurements, specifically:

* **Distance between two selected points:** Calculating the Euclidean distance between any two user-selected points in the 3D view.  
* **Angle between three selected points:** Determining the angle formed by three user-selected points, with the middle point serving as the vertex of the angle.

Finally, the application interface will feature a **dual-panel UI mirroring Faro Scene's registration view**.1 This layout will present two synchronized views side-by-side or in a split configuration. One panel will display the overall scan map, providing contextual awareness of the user's location within the larger point cloud. The other panel will showcase the interactive spherical "street view," allowing detailed exploration. This dual-panel approach is intended to enhance workflow efficiency and contextual understanding.

### **B. Technical Constraints and Platform**

The development of this feature is bound by specific technical constraints to ensure seamless integration and optimal performance within the existing application ecosystem.  
The primary framework for development is **Qt6**.3 All implementation must adhere to the Qt6 API and best practices, necessitating the extensive use of Qt's modern 3D modules, primarily Qt3D, and C++ for performance-critical components. Qt6's updated rendering hardware interface (RHI) and preference for std::vectors in the backend contribute to performance improvements.3  
Crucially, the new feature requires **integration with the existing point cloud application**. This implies that the solution must seamlessly interact with the current application's point cloud loading, management, and display infrastructure. Efficient data transfer mechanisms and compatibility with existing point cloud data formats are paramount to avoid data duplication or conversion overhead.  
A specific requirement for the virtual camera is an **automatic camera offset of 1.6 meters from the floor** \[User Query\]. This means that when a user drops a pin on the scan map, the system must automatically determine the local ground level at that 3D point and position the virtual camera 1.6 meters vertically above it, simulating a human eye-level perspective.

## **III. Architectural Foundation: Leveraging Qt6 for 3D Visualization**

### **A. Choosing the Right Qt 3D Module**

Selecting the appropriate Qt 3D module is fundamental to achieving the desired interactive and immersive "street view" experience. A careful evaluation of Qt3D and QtDataVisualization reveals distinct capabilities and design philosophies.  
QtDataVisualization is primarily designed for analytical and scientific data visualization, offering 3D bar, scatter, and surface graphs.5 It provides ready-made data proxies for visualizing data from Qt item models and height maps, along with user interactions such as rotating graphs, zooming, and selecting items within predefined graph types.5 While it supports 3D scatter graphs, its focus on structured data presentation and limited customizability for arbitrary 3D scenes makes it less suitable for a free-form, dynamic "street view" experience.5 The module's strengths lie in presenting complex data in a structured, visual format, not in building an open-ended interactive 3D environment.  
In contrast, Qt3D offers a fully configurable renderer and a generic framework for near-realtime simulations, built upon an Entity Component System (ECS) architecture.6 This architecture, comprising Entities, Components, and Aspects, promotes modularity and allows for dynamic manipulation of 3D objects and their properties.6 Qt3D provides fine-grained control over rendering pipelines through a "framegraph," which defines *how* a scene is rendered, including different rendering approaches, state sets, and shader switching.6 This level of control is essential for implementing custom rendering techniques required for point cloud visualization, such as point sprites or custom geometry, which are not readily available in QtDataVisualization. The Qt3DRender module, a core part of Qt3D, provides essential C++ classes for defining cameras (QCamera, QCameraLens), encapsulating geometry rendering (QGeometryRenderer), and performing ray casting operations (QAbstractRayCaster, QRayCaster, QScreenRayCaster).8 These capabilities are crucial for constructing the complex and interactive 3D environment demanded by the "street view" feature.  
The choice of Qt3D is therefore driven by its inherent adaptability for custom rendering pipelines. The user's request for a "Google Street View"-like experience necessitates a highly customized 3D rendering scenario, far beyond what standard data plotting tools can offer. Qt3D's explicit design for "fully configurable" rendering and "near-realtime simulations" directly addresses this need.6 The ability to define custom framegraphs and leverage the ECS architecture provides the architectural depth required to implement a non-standard 3D view, allowing for bespoke point cloud rendering and interaction paradigms.

### **B. Integrating Multiple 3D Views in a Qt Widgets Application**

To achieve the desired dual-panel interface, integrating multiple 3D views within a standard Qt Widgets application is a key architectural consideration.  
The primary mechanism for embedding 3D content in a QWidget-based application involves utilizing Qt3DExtras::Qt3DWindow and QWidget::createWindowContainer. Qt3DExtras::Qt3DWindow provides a ready-to-use surface for rendering 3D scenes.9 Since Qt3DWindow is a subclass of QWindow (not QWidget), it cannot be directly added to a QWidget layout. QWidget::createWindowContainer() addresses this by creating a QWidget wrapper for an existing QWindow, allowing it to be seamlessly integrated into any QWidget hierarchy, including QMainWindow layouts.15 This approach ensures optimal performance by allowing the QWindow to render directly without interference from the widgets.16  
The implementation of the dual-panel layout, mirroring Faro Scene's registration view 1, will be achieved using QSplitter. QSplitter is a standard Qt widget that allows users to dynamically control the size of its child widgets by dragging a handle between them.18 Two instances of Qt3DExtras::Qt3DWindow, each wrapped by QWidget::createWindowContainer(), can be added to a QSplitter to create the desired side-by-side display.15 This provides a flexible and user-resizable interface for both the overall scan map and the detailed spherical view.  
A critical aspect of this dual-view setup is synchronizing camera views between the overall map and the detailed spherical view. While Qt3D supports rendering a scenegraph from multiple viewports using different virtual cameras 7, the nature of the two views in this application necessitates distinct camera behaviors. The main map camera will likely employ a free-roaming control scheme, such as Qt3DExtras::QOrbitCameraController, for general navigation.9 In contrast, the spherical view camera must remain statically positioned at the user-pinned location, allowing only rotation (panning and tilting) around its own origin \[User Query\]. This is not a simple "link two cameras" problem but rather requires careful management of camera properties. When a pin is dropped on the main map, its 3D coordinates will be used to precisely set the position of the spherical view camera. Conversely, as the user pans within the spherical view, its orientation could dynamically update a visual indicator, such as a frustum or cone, on the main map view to show the current field of view. QCamera::setPosition() and QCamera::setViewCenter() are key methods for programmatic camera control in Qt3D.9 The fundamental difference in how these cameras operate means that a standard QOrbitCameraController might not be sufficient for the spherical view, necessitating a custom controller focused purely on fixed-point rotation.  
**Table 1: Key Qt3D Modules and Classes for 3D Scene Setup**

| Category | Qt3D Module | Key Classes | Description | Relevant Snippets |
| :---- | :---- | :---- | :---- | :---- |
| **Scene Graph Core** | Qt3DCore | QEntity | Represents an object in the 3D scene, composed of components. | 6 |
|  |  | QComponent | Base class for adding behavior/data to entities. | 6 |
|  |  | QTransform | Defines position, rotation, and scale of entities. | 9 |
|  |  | QGeometry | Encapsulates vertex data (positions, normals, etc.). | 8 |
|  |  | QBuffer | Provides data store for raw vertex/index data. | 37 |
|  |  | QAttribute | Defines how data is read from a QBuffer for rendering. | 37 |
| **Rendering** | Qt3DRender | QCamera | Defines the viewpoint for rendering the scene. | 8 |
|  |  | QCameraLens | Specifies the projection matrix (e.g., perspective). | 8 |
|  |  | QGeometryRenderer | Encapsulates geometry rendering, specifying primitive type (e.g., points, lines). | 8 |
|  |  | QMaterial | Defines how light interacts with the surface (shaders). | 6 |
|  |  | QEffect | Base class for rendering effects. | 8 |
|  |  | QShader / QShaderProgram | Used for custom vertex/fragment shaders. | 4 |
|  |  | QFrameGraphNode | Base for configuring rendering pipeline (e.g., Viewport, ClearBuffers). | 7 |
|  |  | QFrustumCulling | Enables culling of objects outside the camera's view frustum. | 8 |
| **UI Integration** | Qt3DExtras | Qt3DWindow | A QWindow subclass for rendering 3D scenes. | 9 |
|  | QtWidgets | QWidget::createWindowContainer() | Embeds a QWindow (like Qt3DWindow) into a QWidget hierarchy. | 15 |
|  | QtWidgets | QSplitter | Provides resizable divisions for arranging widgets (e.g., dual-panel layout). | 18 |
|  | Qt3DExtras | QOrbitCameraController | Provides basic orbital camera controls (useful for main map). | 9 |

## **IV. Generating the Spherical "Street View"**

### **A. Virtual Camera Placement and Orientation**

Accurate placement and orientation of the virtual camera are paramount for creating a convincing "street view" experience. The user's interaction begins with a 2D pin-drop on the scan map, which corresponds to a 3D (X, Y, Z) coordinate within the loaded point cloud.  
The first critical step is **determining the "floor" at the pinned point and applying the 1.6m vertical offset** \[User Query\]. Point clouds, especially those generated from SLAM, are often unstructured and lack explicit ground plane information. Simply taking the lowest Z-value in the entire cloud is insufficient, as this might correspond to a point far from the pinned location or an outlier. Therefore, a local floor detection algorithm is necessary. This involves performing a local neighborhood search around the X, Y coordinates of the pinned point within the point cloud. Efficient spatial data structures, such as K-D trees or Octrees, are crucial for rapidly identifying points within a small cylindrical or spherical region around the pinned location.31 Within this local cluster of points, the lowest Z-value, or an average of the lowest Z-values (possibly after outlier removal), can be robustly identified as the local "floor" level. The virtual camera's Z-coordinate will then be precisely set to floor\_Z \+ 1.6m, while its X and Y coordinates will match those of the pinned point. This ensures a consistent and realistic eye-level perspective.  
Once the 3D position (X, Y, Z \+ 1.6m) is established, an instance of Qt3DRender::QCamera will be either created or repositioned. Its setPosition() method will be used to set the camera's origin to this calculated point.9 The setViewCenter() method will initially be set to a point slightly in front of the camera, defining its initial forward direction (e.g., position \+ (0,0,-1) in a Z-forward coordinate system).9 The QCameraLens component will define the perspective projection, setting parameters such as field of view, aspect ratio, and near/far clipping planes.8  
The requirement for **implementing fixed-point rotation (panning) around the virtual camera's position** is distinct from typical orbital camera controls. Unlike a camera that orbits an object, this virtual camera must remain stationary at the pinned point, allowing only its orientation to change, simulating a 360-degree view from a fixed vantage point. This means the QCamera::position property remains constant, and only its viewCenter and upVector properties are manipulated to simulate panning and tilting.29 A custom camera controller, potentially inheriting from QAbstractCameraController or directly manipulating QCamera properties, will be necessary. This controller will interpret mouse input (e.g., click-and-drag gestures) to update the viewCenter by rotating a direction vector around the camera's fixed position. Quaternions offer a robust and efficient mathematical representation for handling complex 3D rotations without issues like gimbal lock.29

### **B. Point Cloud to Spherical Image Projection (Ray Casting)**

The core challenge in generating the spherical "street view" lies in transforming the discrete, potentially sparse, point cloud data into a continuous, immersive panoramic image.  
The fundamental approach involves **conceptualizing ray casting from the virtual camera's origin into the point cloud**. From the virtual camera's fixed position, rays are cast in all directions (360 degrees horizontally and vertically).38 For each ray, the system must identify the closest point in the point cloud that it intersects. The color and depth of this intersected point then determine the color and depth of a corresponding pixel in the resulting spherical image. This process is a form of "point-based rendering" or "ray tracing point clouds".39  
Raw point clouds can be sparse, leading to "holes" or gaps in the ray-traced image if a ray does not intersect any point.39 To address this and generate a dense spherical image, several **strategies for handling point cloud sparsity and generating a dense spherical image** can be employed:

* **Direct Point Rendering:** A basic approach involves rendering the point cloud directly as point sprites or small spheres, with their size adjusted based on distance to visually fill gaps.42 However, this might result in a less smooth or "pixelated" appearance compared to a true panoramic image.  
* **Cubemap/Equirectangular Generation via Ray Casting:** A more sophisticated and visually appealing approach involves generating a cubemap (six 2D images representing the faces of a cube) or a single equirectangular panoramic image.40 This is achieved by casting rays from the camera position onto the faces of a conceptual cube or sphere. For each ray, the nearest point in the point cloud is identified, and its color is mapped to the corresponding pixel in the cubemap or equirectangular image.39  
* **Hole Filling/Interpolation:** To further mitigate sparsity artifacts, techniques like nearest neighbor interpolation 33 or surface reconstruction 42 can be applied to the ray-hit points to generate a denser, smoother image. Research indicates that "splat-based ray tracing methods approximate point cloud surfaces by planar circular or elliptical disks" 39, which can effectively reduce visual artifacts. Additionally, neural mono-ocular depth estimation could be explored to generate synthetic depth maps from existing image data, which could then be used for displacement mapping to create a more continuous surface.43

The computational intensity of ray casting into raw point clouds, especially large ones, is a significant challenge. Direct ray casting into millions of unstructured points for every pixel of a high-resolution spherical image (e.g., six 1024x1024 cubemap faces) is computationally prohibitive.38 This is a classic N-body problem for intersection, meaning that efficient spatial acceleration structures are not just beneficial but absolutely necessary for real-time performance. Octrees and K-D trees are prime candidates for accelerating nearest neighbor and ray intersection queries in point clouds.31 Without these structures, interactive performance would be impossible. Furthermore, the concept of "progressive rendering" becomes highly relevant here: instead of rendering the entire spherical view at once, it can be progressively refined over multiple frames to maintain interactivity.56 This approach starts with a quick, potentially lower-quality initial pass and then refines it to full detail over subsequent frames, directly addressing the need for real-time interaction while acknowledging the inherent computational challenges of point cloud visualization. This progressive approach represents a crucial trade-off between visual quality and performance for spherical views, offering a middle ground that balances responsiveness with visual fidelity.  
For **consideration of cubemap generation from point clouds and subsequent equirectangular projection for display**:

* **Cubemap Generation:** A cubemap is a texture composed of six individual 2D textures, each forming one side of a cube, which can be indexed using a direction vector.45 For point clouds, this involves projecting the surrounding points onto the six faces of a conceptual cube centered at the virtual camera's origin.46 This process can be implemented by iterating through the loaded point cloud, determining which cubemap face each point projects onto, and then coloring the corresponding pixel in that face's texture. Techniques like "surface splatting" 46 can be employed to create smooth, hole-less projections, especially important in sparse areas.  
* **Equirectangular Projection:** If a single, continuous panoramic image is preferred for display (as is common in Street View), the six generated cubemap faces can be converted into an equirectangular projection using established mathematical transformations.48 This involves mapping spherical coordinates (latitude and longitude) to 2D pixel coordinates on the equirectangular image plane.

### **C. Rendering the Spherical View**

Once the cubemap or equirectangular image is generated, either through an initial processing step or progressively over time, it must be efficiently rendered to create the immersive spherical view.  
The primary method for rendering the spherical view involves **applying the generated spherical image as a texture on a large sphere or cubemap surrounding the virtual camera**. If a cubemap texture is generated, it can be applied to a large Qt3DExtras::QCuboidMesh (or a custom QGeometry representing a cube) centered precisely around the virtual camera.45 The camera itself must be positioned at the exact center of this textured object. If an equirectangular panoramic image is generated, it can be mapped onto a large Qt3DExtras::QSphereMesh or a custom spherical QGeometry.48 This approach creates the illusion that the user is inside a continuous environment.  
**Implementing user interaction for panning and tilting the spherical view** is crucial for an intuitive experience. As discussed in Section IV.A, a custom camera controller will be developed to handle mouse input. Instead of altering the camera's position, this controller will manipulate the viewCenter and upVector properties of the Qt3DRender::QCamera instance.29 By rotating the viewCenter around the fixed camera position, the view of the surrounding textured sphere or cubemap will pan and tilt, providing the immersive 360-degree exploration capability. While Qt3DExtras::QOrbitCameraController provides a basis for rotation around a point, it may require modification to ensure the camera remains fixed at the pinned location and only its orientation changes.9

## **V. Interactive Features: Picking and Measurement**

### **A. Object/Feature Picking in 3D**

Enabling users to interact with features within the 3D spherical view is critical for the application's utility.  
The primary method for **implementing point selection (picking) will utilize Qt3DRender::QObjectPicker**.8 QObjectPicker is a C++ component that performs ray-casting from screen coordinates into the 3D scene to identify entities whose bounding volumes intersect the ray.57 It emits signals such as clicked(), entered(), and exited(), providing a QPickEvent instance with detailed hit information.57 While QtQuick3D::View3D::pick() serves a similar purpose in QML 62, QObjectPicker is the direct C++ choice for this project.  
Upon a successful pick, it is essential to **retrieve the precise 3D coordinates of the picked points**. The QPickEvent object returned by QObjectPicker contains a worldIntersection() method, which provides the 3D world coordinates of the intersection point.60 This precise coordinate is fundamental for subsequent measurement calculations.  
A significant consideration arises when picking sparse point clouds versus solid meshes. QObjectPicker primarily works by casting rays and checking for intersections with the *bounding volumes* of QEntity objects.57 If the entire point cloud is rendered as a single large QGeometryRenderer with individual points, accurately picking individual points or even small clusters like target boards or spheres can be challenging. While QPickEvent can return a QPickPointEvent 8, its reliability for precise individual point selection in highly sparse data requires careful testing. A more robust approach to address this challenge would involve:

1. **Pre-segmenting known features** (e.g., target boards, spheres) into separate QEntity objects, each with its own defined bounding volume. This makes these specific features explicitly pickable by the QObjectPicker.  
2. If the user clicks on a "general" point within the larger point cloud, a **nearest-neighbor search** to the ray intersection point (leveraging efficient spatial data structures like Octrees or K-D trees) would be performed to identify the actual 3D point in the raw data that was intended, rather than solely relying on the bounding volume of the entire cloud. This approach provides a more accurate and reliable interaction for sparse data.

Finally, to provide clear feedback, **selected features will be highlighted through visual cues** such as a color change, the display of a temporary bounding box, or a custom highlight effect applied via shaders. This visual feedback confirms the user's selection.62

### **B. Real-time Measurement Tools**

The ability to perform interactive 3D measurements directly within the spherical view is a core requirement.  
To visualize measurements, the system will dynamically **draw temporary 3D lines between two or more picked points using Qt3DRender::QGeometryRenderer and custom QGeometry**. Qt3DCore::QGeometry allows for the definition of custom vertex data and indices.8 For a simple line, this would involve defining two vertices (start and end points) and two indices (connecting them). Qt3DRender::QGeometryRenderer, configured with the Lines primitive type, would then render this custom geometry.8 These temporary line geometries would be added as child entities to the scene's root entity, allowing them to be dynamically created and removed.  
For numerical measurements, the system will **calculate Euclidean distances between picked points**. Given two picked 3D points (P1 and P2) obtained from QPickEvent::worldIntersection(), the Euclidean distance is a straightforward vector calculation: distance \= (P2 \- P1).length(). Qt's QVector3D class provides the length() method for this purpose.  
To calculate angles, the system will determine **angles between three picked points**. For three picked points (P1, P2, and P3), the angle at the middle point (P2) can be calculated using the dot product of the two vectors formed by these points (P2-P1 and P2-P3). The standard formula is angle \= acos(dot\_product(V1, V2) / (length(V1) \* length(V2))).73 QVector3D::dotProduct() and QVector3D::length() methods are directly applicable for these calculations.  
Finally, to present the calculated measurements to the user, they will be **displayed as 3D text annotations**. Qt3DExtras::QText2DEntity can render 2D text labels within the 3D space.63 Alternatively, a custom billboarded geometry can be implemented. This involves rendering a quad (a flat surface) that always faces the camera, with the measurement text rendered onto it as a texture using shaders.14 This "billboarding" technique ensures that the text remains readable regardless of the camera's angle or movement.  
**Table 2: Qt3D Classes for Interactive Picking and Measurement**

| Feature | Qt3D Module | Key Classes/Concepts | Description | Relevant Snippets |
| :---- | :---- | :---- | :---- | :---- |
| **Picking** | Qt3DRender | QObjectPicker | Component for ray-casting based picking of entities. Emits clicked(), entered(), exited() signals. | 8 |
|  |  | QPickEvent | Contains details of a pick event, including worldIntersection() (3D coordinates). | 57 |
|  |  | QPickingSettings | Configures picking behavior (e.g., TrianglePicking, AllPicks). | 8 |
|  |  | QPickPointEvent | Specific event type for picking individual points in a point cloud. | 8 |
| **Measurement** | Qt3DCore | QGeometry | Custom geometry for drawing lines between picked points. | 8 |
|  | Qt3DRender | QGeometryRenderer | Renders the custom QGeometry as lines (Lines primitive type). | 8 |
|  | Qt3DExtras | QText2DEntity | Displays 2D text labels in 3D space for measurements. | 63 |
|  | QVector3D | (Mathematical operations) | For calculating Euclidean distance (length()) and angles (dotProduct(), acos()). | 73 |

## **VI. Performance Optimization for Large Point Clouds**

Handling large point cloud datasets (e.g., 20 million points 81) in real-time interactive applications demands significant performance optimization. The strategies employed will span efficient data structures and advanced rendering pipeline techniques, reflecting a fundamental shift towards GPU-bound optimization.

### **A. Efficient Data Structures**

Point clouds, especially those derived from SLAM scans, are inherently unstructured collections of 3D points. Performing operations like ray intersections or nearest neighbor queries on millions of such points using linear searches would be prohibitively slow, making real-time interaction impossible. Therefore, the implementation of spatial partitioning structures is crucial for accelerating these operations.  
**Spatial partitioning structures like Octrees or K-D trees** are essential for accelerated ray casting and nearest neighbor queries.

* **Octrees** recursively subdivide 3D space into eight octants, allowing for efficient culling of irrelevant regions and rapid nearest neighbor searches.31 They are particularly well-suited for irregular point cloud data and form the basis for many Level of Detail (LOD) generation techniques.82  
* **K-D trees** are binary trees that partition space along one of the coordinate axes at each node, enabling efficient range searches and nearest neighbor queries.33 They offer logarithmic time complexity for searches on average, making them highly effective for large datasets.35 Both Octrees and K-D trees are crucial for optimizing the ray casting process used to generate the spherical view 39, as well as for efficient picking operations 57 and the precise floor detection required for camera placement.

The **Point Cloud Library (PCL)** is an invaluable open-source C++ library that provides a wide array of algorithms for point cloud processing tasks, including filtering, feature estimation, surface reconstruction, and 3D registration.84 PCL supports various point cloud data formats, including its own PCD format.84 It integrates with Qt for GUI development 84, and some existing PCL-based viewers already leverage Qt for their interfaces.85 PCL offers critical pre-processing capabilities such as VoxelGrid filters for downsampling and various outlier removal filters 84, which are vital for managing large, noisy datasets. While Qt3D can render points directly, PCL can be used for these initial data preparation steps, or even for providing the underlying spatial data structure, provided its integration with Qt3D's rendering pipeline is carefully managed to ensure data consistency and avoid performance bottlenecks. The role of pre-processing in achieving real-time performance is significant. The raw point clouds, especially from SLAM, can be very large and noisy. By leveraging PCL's filtering and downsampling capabilities, the overall data size and complexity processed by the rendering pipeline can be substantially reduced. This is a critical step that directly impacts the feasibility of real-time rendering and enables more effective Level of Detail strategies.

### **B. Rendering Pipeline Optimizations**

Beyond efficient data structures, several rendering pipeline optimizations are necessary to ensure a smooth and interactive experience with large point clouds.  
**Leveraging Qt3DRender::QFrustumCulling** is a fundamental optimization. This FrameGraph node enables the culling of entities (including point cloud segments) that fall outside the camera's current view frustum.8 By rendering only the points that are actually visible to the camera, significant performance gains can be achieved, reducing the amount of data sent to the GPU. While effective, frustum culling alone may not be sufficient for extremely dense point clouds.81  
To further manage rendering complexity, **Level of Detail (LOD) strategies for adaptive rendering based on distance** will be implemented.

* Qt3D provides QLevelOfDetail and QLevelOfDetailSwitch classes, which allow controlling the complexity of rendered entities based on their size on the screen or their distance from the camera.8 This enables rendering coarser representations of the point cloud when the camera is far away and progressively revealing more detail as the camera moves closer.  
* More advanced LOD for point clouds often involves a hierarchical structure like an Octree, where inner nodes store simplified representations (e.g., voxels or centroids) and leaf nodes store full-resolution points.82 This allows for dynamic selection of the appropriate level of detail based on the camera's position and zoom level, ensuring that only necessary detail is rendered. Libraries like SimLOD demonstrate real-time, GPU-accelerated octree-based LOD generation and rendering for massive point clouds, achieving high throughput by processing data directly on the GPU.82

**Exploring progressive rendering techniques** is vital for smoother interaction with very large datasets. Progressive rendering breaks down the rendering of a complex scene into multiple frames, accumulating detail over time.56 This is particularly beneficial for large point clouds where a full, high-quality render in a single frame would be too costly and lead to stuttering. This technique ensures that the user always sees an interactive, albeit initially lower-quality, view that then refines to full detail as rendering progresses.56 The "Reprojection" stage, which reuses information from previously visible points, can significantly accelerate the initial visualization immediately after camera movement.56 This approach directly addresses the need for real-time responsiveness by distributing the computational load over time.  
For efficient point rendering, **utilizing OpenGL shaders (GLSL) and Vertex Buffer Objects (VBOs)** is standard practice.

* Point cloud data (including X, Y, Z coordinates, color, and potentially normals) should be stored in Vertex Buffer Objects (VBOs) on the GPU.87 This minimizes costly data transfers between the CPU and GPU, as the data resides directly in GPU memory.  
* Custom GLSL shaders will be employed to render the points. The vertex shader can control gl\_PointSize to ensure that points appear to have a consistent fixed size in 3D space, rather than just on the screen, which is crucial for maintaining visual fidelity during zooming.42 The fragment shader is responsible for calculating the color of each pixel 4, allowing for advanced visual effects such as lighting, color adjustments, and potentially Eye-Dome Lighting 56 for enhanced depth perception and surface definition.

Finally, for extremely large point clouds and complex real-time processing tasks (such as advanced ray casting for spherical views or dynamic LOD updates), **consideration of CUDA-OpenGL interop for GPU-accelerated point cloud processing and rendering** is essential. This technique allows for direct sharing of data between CUDA (for general-purpose GPU computation) and OpenGL (for rendering) without the need for costly intermediate transfers to CPU memory.90 This interoperation can provide significant performance gains by keeping data entirely on the GPU. SimLOD, for example, implements its LOD construction and rendering entirely in CUDA, demonstrating the potential for handling massive point clouds at very high frame rates.82 The shift from predominantly CPU-bound processing to leveraging the parallel processing power of GPUs is a key factor in achieving the required real-time performance for this application.

## **VII. Conclusion and Recommendations**

The development of an interactive 3D point cloud "street view" feature within a Qt6 application is technically feasible and can deliver a highly immersive and functional user experience. The analysis confirms that Qt3D is the most appropriate framework due to its configurable renderer, Entity Component System (ECS) architecture, and granular control over the rendering pipeline, which are essential for custom 3D scene generation and interaction. Embedding these 3D views within a Qt Widgets application is achievable using QWidget::createWindowContainer() and QSplitter for the dual-panel layout.  
The primary technical challenges lie in the efficient generation and real-time rendering of the spherical panoramic view from potentially sparse and large point clouds, as well as precise interaction with these points. These challenges necessitate a robust architectural approach centered on performance optimization.  
**Recommendations for Implementation:**

1. **Adopt Qt3D as the Core 3D Framework:** Implement the 3D visualization using Qt3DCore, Qt3DRender, and Qt3DExtras. This provides the necessary flexibility for custom geometries, materials, shaders, and camera controls.  
2. **Implement a Dual-Panel UI with QSplitter:** Create two Qt3DExtras::Qt3DWindow instances, each wrapped in a QWidget using QWidget::createWindowContainer(), and arrange them within a QSplitter to achieve the desired Faro Scene-like layout.  
3. **Develop Custom Camera Controllers for Synchronization:**  
   * For the main map view, QOrbitCameraController can serve as a starting point.  
   * For the spherical view, develop a custom camera controller that fixes the camera's position at the pinned point and only allows rotation of its viewCenter and upVector to simulate 360-degree panning and tilting.  
   * Implement logic to synchronize the pinned location on the main map with the spherical view camera's position, and potentially display the spherical view's frustum on the main map.  
4. **Prioritize Efficient Spatial Data Structures:** Integrate and utilize spatial partitioning structures such as **Octrees** or **K-D trees** for the point cloud data. These structures are critical for accelerating ray casting queries (for spherical image generation), nearest neighbor searches (for floor detection and precise picking), and overall data management.  
5. **Implement a Ray Casting-Based Spherical Image Generation Pipeline:**  
   * Cast rays from the virtual camera's position into the point cloud (leveraging the spatial data structure for efficiency).  
   * Generate either a cubemap (six 2D textures) or a single equirectangular panoramic image from the ray intersections.  
   * Apply techniques like "surface splatting" or interpolation to mitigate sparsity and fill holes in the generated image.  
   * Render this generated image as a texture on a large sphere or cuboid mesh centered around the virtual camera.  
6. **Integrate Robust Picking and Measurement Tools:**  
   * Utilize Qt3DRender::QObjectPicker to enable feature selection.  
   * For accurate picking of individual points in sparse clouds, implement a nearest-neighbor search to the ray intersection point, rather than solely relying on bounding volumes.  
   * Dynamically draw measurement lines and display 3D text annotations using custom QGeometry and Qt3DExtras::QText2DEntity (or billboarded geometry).  
7. **Implement Comprehensive Performance Optimizations:**  
   * **Data Pre-processing:** Consider using external libraries like PCL for initial filtering, downsampling, and noise reduction of large point clouds to reduce the data load on the rendering pipeline.  
   * **LOD Strategies:** Implement Level of Detail (LOD) using Qt3D's QLevelOfDetail or more advanced Octree-based LOD techniques to adapt rendering complexity based on distance.  
   * **Progressive Rendering:** Explore progressive rendering techniques to maintain interactivity with very large datasets by incrementally refining the spherical view over multiple frames.  
   * **GPU Acceleration:** Leverage OpenGL shaders (GLSL) and Vertex Buffer Objects (VBOs) for efficient point rendering. For extreme performance needs, investigate CUDA-OpenGL interop for GPU-accelerated processing of point cloud data before rendering.

By meticulously addressing these recommendations, the development team can build a high-performance, intuitive, and feature-rich interactive 3D point cloud "street view" capability that significantly enhances the existing application.

#### **Works cited**

1. New REGISTRATION Feature in FARO SCENE 2023 \- YouTube, accessed on May 31, 2025, [https://www.youtube.com/watch?v=NGt9olyG0YQ](https://www.youtube.com/watch?v=NGt9olyG0YQ)  
2. Interactive Registration Workflow in SCENE \- FARO® Knowledge Base, accessed on May 31, 2025, [https://knowledge.faro.com/Software/FARO\_SCENE/SCENE/Interactive\_Registration\_Workflow\_in\_SCENE](https://knowledge.faro.com/Software/FARO_SCENE/SCENE/Interactive_Registration_Workflow_in_SCENE)  
3. Qt 3D Renderer changes and improvements in Qt 6 \- KDAB, accessed on May 31, 2025, [https://www.kdab.com/qt3d-renderer-qt6/](https://www.kdab.com/qt3d-renderer-qt6/)  
4. Graphics Shaders | The Qt 6 Book, accessed on May 31, 2025, [https://www.qt.io/product/qt6/qml-book/ch10-effects-opengl-shaders](https://www.qt.io/product/qt6/qml-book/ch10-effects-opengl-shaders)  
5. Qt Data Visualization Overview \- Felgo, accessed on May 31, 2025, [https://felgo.com/doc/qt/qtdatavisualization-overview/](https://felgo.com/doc/qt/qtdatavisualization-overview/)  
6. Qt 3D Overview | Qt 3D | Qt Documentation (Pro) \- Felgo, accessed on May 31, 2025, [https://felgo.com/doc/qt/qt3d-overview/](https://felgo.com/doc/qt/qt3d-overview/)  
7. Qt3D 2.0 The FrameGraph \- KDAB, accessed on May 31, 2025, [https://www.kdab.com/qt3d-2-0-framegraph/](https://www.kdab.com/qt3d-2-0-framegraph/)  
8. Qt 3D Render C++ Classes \- Felgo, accessed on May 31, 2025, [https://felgo.com/doc/qt/qt3drender-module/](https://felgo.com/doc/qt/qt3drender-module/)  
9. Qt 3D: Simple C++ Example \- Felgo, accessed on May 31, 2025, [https://felgo.com/doc/qt/qt3d-simple-cpp-example/](https://felgo.com/doc/qt/qt3d-simple-cpp-example/)  
10. Qt 3D: Simple C++ Example \- Developpez.com, accessed on May 31, 2025, [https://qt.developpez.com/doc/6.5/qt3d-simple-cpp-example/](https://qt.developpez.com/doc/6.5/qt3d-simple-cpp-example/)  
11. Qt3D minimal example using CMake \- Victoria Rudakova, accessed on May 31, 2025, [https://vicrucann.github.io/tutorials/qt3d-cmake/](https://vicrucann.github.io/tutorials/qt3d-cmake/)  
12. Qt 3D: Simple C++ Example | Qt 3D 5.15.1, accessed on May 31, 2025, [https://qthub.com/static/doc/qt5/qt3d/qt3d-simple-cpp-example.html](https://qthub.com/static/doc/qt5/qt3d/qt3d-simple-cpp-example.html)  
13. Qt3d: rotate camera around the object (C++) \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/48604332/qt3d-rotate-camera-around-the-object-c](https://stackoverflow.com/questions/48604332/qt3d-rotate-camera-around-the-object-c)  
14. Qt 3D: Simple C++ Example, accessed on May 31, 2025, [https://doc.qt.io/qt-6/qt3d-simple-cpp-example.html](https://doc.qt.io/qt-6/qt3d-simple-cpp-example.html)  
15. Render a Qt3d view as a widget on QApplication MainWindow \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/37379283/render-a-qt3d-view-as-a-widget-on-qapplication-mainwindow](https://stackoverflow.com/questions/37379283/render-a-qt3d-view-as-a-widget-on-qapplication-mainwindow)  
16. Introducing QWidget::createWindowContainer() \- Qt, accessed on May 31, 2025, [https://www.qt.io/blog/2013/02/19/introducing-qwidgetcreatewindowcontainer](https://www.qt.io/blog/2013/02/19/introducing-qwidgetcreatewindowcontainer)  
17. Show Qt3D stuff inside QWidget in Qt5 \- c++ \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/35074830/show-qt3d-stuff-inside-qwidget-in-qt5](https://stackoverflow.com/questions/35074830/show-qt3d-stuff-inside-qwidget-in-qt5)  
18. How to dock a QDockWidgets inside a QSplitter? \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/55131178/how-to-dock-a-qdockwidgets-inside-a-qsplitter](https://stackoverflow.com/questions/55131178/how-to-dock-a-qdockwidgets-inside-a-qsplitter)  
19. Thread: Arrange Widgets in QSplitter \- Qt Centre Forum, accessed on May 31, 2025, [https://www.qtcentre.org/threads/51022-Arrange-Widgets-in-QSplitter](https://www.qtcentre.org/threads/51022-Arrange-Widgets-in-QSplitter)  
20. QSplitter \- Qt for Python, accessed on May 31, 2025, [https://doc.qt.io/qtforpython-6.5/PySide6/QtWidgets/QSplitter.html](https://doc.qt.io/qtforpython-6.5/PySide6/QtWidgets/QSplitter.html)  
21. C++ Qt 10 \- Splitters \- YouTube, accessed on May 31, 2025, [https://m.youtube.com/watch?v=fR57o\_asTs0](https://m.youtube.com/watch?v=fR57o_asTs0)  
22. Qt3D Multiple Viewports with C++ \- Qt Forum, accessed on May 31, 2025, [https://forum.qt.io/topic/88801/qt3d-multiple-viewports-with-c](https://forum.qt.io/topic/88801/qt3d-multiple-viewports-with-c)  
23. Qt 3D: Multi Viewport QML Example \- Qt for Python, accessed on May 31, 2025, [https://doc.qt.io/qtforpython-6.5/overviews/qt3d-multiviewport-example.html](https://doc.qt.io/qtforpython-6.5/overviews/qt3d-multiviewport-example.html)  
24. Qt 3D: Multi Viewport QML Example | Qt 3D | Qt 6.9.0, accessed on May 31, 2025, [https://doc.qt.io/qt-6/qt3d-multiviewport-example.html](https://doc.qt.io/qt-6/qt3d-multiviewport-example.html)  
25. Qt 3D: Multi Viewport QML Example, accessed on May 31, 2025, [https://stuff.mit.edu/afs/athena/software/texmaker\_v5.0.2/qt57/doc/qt3d/qt3d-multiviewport-example.html](https://stuff.mit.edu/afs/athena/software/texmaker_v5.0.2/qt57/doc/qt3d/qt3d-multiviewport-example.html)  
26. Qt3DExtras::QOrbitCameraController Class | Qt 3D | Qt 6.9.0 \- Qt Documentation, accessed on May 31, 2025, [https://doc.qt.io/qt-6/qt3dextras-qorbitcameracontroller.html](https://doc.qt.io/qt-6/qt3dextras-qorbitcameracontroller.html)  
27. QOrbitCameraController Class | Qt 3D 5.15.1, accessed on May 31, 2025, [https://qthub.com/static/doc/qt5/qt3d/qt3dextras-qorbitcameracontroller.html](https://qthub.com/static/doc/qt5/qt3d/qt3dextras-qorbitcameracontroller.html)  
28. How to zoom toward a 3D mesh with qt? \- c++ \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/51708350/how-to-zoom-toward-a-3d-mesh-with-qt](https://stackoverflow.com/questions/51708350/how-to-zoom-toward-a-3d-mesh-with-qt)  
29. How to rotate camera centered around the camera's position? \- Game Development Stack Exchange, accessed on May 31, 2025, [https://gamedev.stackexchange.com/questions/43588/how-to-rotate-camera-centered-around-the-cameras-position](https://gamedev.stackexchange.com/questions/43588/how-to-rotate-camera-centered-around-the-cameras-position)  
30. Shadow Mapping in Qt3D 2.0 \- KDAB, accessed on May 31, 2025, [https://www.kdab.com/shadow-mapping-qt3d-2-0/](https://www.kdab.com/shadow-mapping-qt3d-2-0/)  
31. Octree \- Open3D primary (unknown) documentation, accessed on May 31, 2025, [https://www.open3d.org/docs/latest/tutorial/geometry/octree.html](https://www.open3d.org/docs/latest/tutorial/geometry/octree.html)  
32. A simple Octree structure that can build up on the Point Clouds \- GitHub, accessed on May 31, 2025, [https://github.com/bertaye/Octree](https://github.com/bertaye/Octree)  
33. Inferior performance of the kd-tree for K-NN point cloud neighbor searches \- MathWorks, accessed on May 31, 2025, [https://www.mathworks.com/matlabcentral/answers/2177225-inferior-performance-of-the-kd-tree-for-k-nn-point-cloud-neighbor-searches](https://www.mathworks.com/matlabcentral/answers/2177225-inferior-performance-of-the-kd-tree-for-k-nn-point-cloud-neighbor-searches)  
34. How to implement nearest neighbour lookup in a point cloud? : r/MachineLearning \- Reddit, accessed on May 31, 2025, [https://www.reddit.com/r/MachineLearning/comments/40sdn6/how\_to\_implement\_nearest\_neighbour\_lookup\_in\_a/](https://www.reddit.com/r/MachineLearning/comments/40sdn6/how_to_implement_nearest_neighbour_lookup_in_a/)  
35. k-d tree \- Wikipedia, accessed on May 31, 2025, [https://en.wikipedia.org/wiki/K-d\_tree](https://en.wikipedia.org/wiki/K-d_tree)  
36. Collision detection between point clouds using an efficient k-d tree implementation, accessed on May 31, 2025, [https://www.researchgate.net/publication/274460697\_Collision\_detection\_between\_point\_clouds\_using\_an\_efficient\_k-d\_tree\_implementation](https://www.researchgate.net/publication/274460697_Collision_detection_between_point_clouds_using_an_efficient_k-d_tree_implementation)  
37. Qt 3D Render C++ Classes, accessed on May 31, 2025, [https://doc.qt.io/qt-5/qt3drender-module.html](https://doc.qt.io/qt-5/qt3drender-module.html)  
38. A Ray Launching Approach for Computing Exact Paths with Point Clouds \- arXiv, accessed on May 31, 2025, [https://arxiv.org/html/2402.13747v1](https://arxiv.org/html/2402.13747v1)  
39. www.zora.uzh.ch, accessed on May 31, 2025, [https://www.zora.uzh.ch/id/eprint/264119/1/RT3DPointCloud.pdf](https://www.zora.uzh.ch/id/eprint/264119/1/RT3DPointCloud.pdf)  
40. Ray Tracing a point cloud : r/computervision \- Reddit, accessed on May 31, 2025, [https://www.reddit.com/r/computervision/comments/176vwb6/ray\_tracing\_a\_point\_cloud/](https://www.reddit.com/r/computervision/comments/176vwb6/ray_tracing_a_point_cloud/)  
41. Raycasting in C++ \#7 | Raycasting Algorithm Part 2 \- YouTube, accessed on May 31, 2025, [https://www.youtube.com/watch?v=DmZD4JcSqHY](https://www.youtube.com/watch?v=DmZD4JcSqHY)  
42. Point Based Rendering : r/opengl \- Reddit, accessed on May 31, 2025, [https://www.reddit.com/r/opengl/comments/1gbsebi/point\_based\_rendering/](https://www.reddit.com/r/opengl/comments/1gbsebi/point_based_rendering/)  
43. Point Cloud from a single 360 image : r/photogrammetry \- Reddit, accessed on May 31, 2025, [https://www.reddit.com/r/photogrammetry/comments/179fu25/point\_cloud\_from\_a\_single\_360\_image/](https://www.reddit.com/r/photogrammetry/comments/179fu25/point_cloud_from_a_single_360_image/)  
44. (PDF) 3D Point-Cloud Processing Using Panoramic Images for ..., accessed on May 31, 2025, [https://www.researchgate.net/publication/380722034\_3D\_Point-Cloud\_Processing\_Using\_Panoramic\_Images\_for\_Object\_Detection](https://www.researchgate.net/publication/380722034_3D_Point-Cloud_Processing_Using_Panoramic_Images_for_Object_Detection)  
45. Cubemaps \- LearnOpenGL, accessed on May 31, 2025, [https://learnopengl.com/Advanced-OpenGL/Cubemaps](https://learnopengl.com/Advanced-OpenGL/Cubemaps)  
46. The cube map generated by projecting the surrounding point cloud onto 6... \- ResearchGate, accessed on May 31, 2025, [https://www.researchgate.net/figure/The-cube-map-generated-by-projecting-the-surrounding-point-cloud-onto-6-faces-of-a-cube\_fig2\_338879396](https://www.researchgate.net/figure/The-cube-map-generated-by-projecting-the-surrounding-point-cloud-onto-6-faces-of-a-cube_fig2_338879396)  
47. SCENE C++ API: Processing \- FARO Developer Portal, accessed on May 31, 2025, [https://developer.faro.com/scene\_api/group\_\_processing.html](https://developer.faro.com/scene_api/group__processing.html)  
48. c++ \- Equirectangular to Cubic with point to point mapping? \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/30700860/equirectangular-to-cubic-with-point-to-point-mapping](https://stackoverflow.com/questions/30700860/equirectangular-to-cubic-with-point-to-point-mapping)  
49. C++ algorithm to convert a fisheye image to an equirectangular image with OpenCV4, accessed on May 31, 2025, [https://stackoverflow.com/questions/56901894/c-algorithm-to-convert-a-fisheye-image-to-an-equirectangular-image-with-opencv](https://stackoverflow.com/questions/56901894/c-algorithm-to-convert-a-fisheye-image-to-an-equirectangular-image-with-opencv)  
50. Cubic to equirectangular projection algorithm \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/11504584/cubic-to-equirectangular-projection-algorithm](https://stackoverflow.com/questions/11504584/cubic-to-equirectangular-projection-algorithm)  
51. Ray Tracing \- The blog at the bottom of the sea, accessed on May 31, 2025, [https://blog.demofox.org/category/ray-tracing/](https://blog.demofox.org/category/ray-tracing/)  
52. Ray Marching \- The Graphics Codex, accessed on May 31, 2025, [https://graphicscodex.com/app/app.html?page=\_rn\_rayMrch](https://graphicscodex.com/app/app.html?page=_rn_rayMrch)  
53. How to Convert a Point Cloud to a 3D Mesh in Python and C++ \- MeshLib, accessed on May 31, 2025, [https://meshlib.io/feature/point-cloud-to-mesh/](https://meshlib.io/feature/point-cloud-to-mesh/)  
54. MeshLab, accessed on May 31, 2025, [https://www.meshlab.net/](https://www.meshlab.net/)  
55. eduardohenriquearnold/oaktree: C++ Ray caster for point clouds using Octrees \- GitHub, accessed on May 31, 2025, [https://github.com/eduardohenriquearnold/oaktree](https://github.com/eduardohenriquearnold/oaktree)  
56. High-Definition Point Clouds: A Close Look at Typhoons New ..., accessed on May 31, 2025, [https://www.plainconcepts.com/high-definition-point-clouds/](https://www.plainconcepts.com/high-definition-point-clouds/)  
57. Qt3DRender::QObjectPicker Class | Qt 3D | Qt 6.9.0, accessed on May 31, 2025, [https://doc.qt.io/qt-6/qt3drender-qobjectpicker.html](https://doc.qt.io/qt-6/qt3drender-qobjectpicker.html)  
58. Qt 3D QML Types \- Developpez.com, accessed on May 31, 2025, [https://qt.developpez.com/doc/6.6/qt3d-qml/](https://qt.developpez.com/doc/6.6/qt3d-qml/)  
59. Qt 3D C++ Classes \- Qt Documentation, accessed on May 31, 2025, [https://doc.qt.io/qt-6/qt3d-cpp.html](https://doc.qt.io/qt-6/qt3d-cpp.html)  
60. Qt3D picking triangles \- Qt Forum, accessed on May 31, 2025, [https://forum.qt.io/topic/71893/qt3d-picking-triangles](https://forum.qt.io/topic/71893/qt3d-picking-triangles)  
61. Qt3D, get object picked with QPickEvent \- c++ \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/46874621/qt3d-get-object-picked-with-qpickevent](https://stackoverflow.com/questions/46874621/qt3d-get-object-picked-with-qpickevent)  
62. Qt Quick 3D \- Picking example \- Qt Documentation, accessed on May 31, 2025, [https://doc.qt.io/qt-6/qtquick3d-picking-example.html](https://doc.qt.io/qt-6/qtquick3d-picking-example.html)  
63. Qt Quick 3D \- Custom Geometry Example \- Developpez.com, accessed on May 31, 2025, [https://qt.developpez.com/doc/6.6/qtquick3d-customgeometry-example/](https://qt.developpez.com/doc/6.6/qtquick3d-customgeometry-example/)  
64. Qt3D Geometry | GammaRay User Manual, accessed on May 31, 2025, [https://docs.kdab.com/gammaray-manual/latest/gammaray-qt3d-geometry-example.html](https://docs.kdab.com/gammaray-manual/latest/gammaray-qt3d-geometry-example.html)  
65. Qt Quick 3D \- Custom Geometry Example \- Developpez.com, accessed on May 31, 2025, [https://qt.developpez.com/doc/6.5/qtquick3d-customgeometry-main-qml/](https://qt.developpez.com/doc/6.5/qtquick3d-customgeometry-main-qml/)  
66. Qt3D adding custom geometry from arrays & creating entities? \- Qt Forum, accessed on May 31, 2025, [https://forum.qt.io/topic/87488/qt3d-adding-custom-geometry-from-arrays-creating-entities](https://forum.qt.io/topic/87488/qt3d-adding-custom-geometry-from-arrays-creating-entities)  
67. qtquick3d-examples-customgeometry.qdoc \- GitHub, accessed on May 31, 2025, [https://github.com/qt/qtquick3d/blob/dev/examples/quick3d/customgeometry/doc/src/qtquick3d-examples-customgeometry.qdoc](https://github.com/qt/qtquick3d/blob/dev/examples/quick3d/customgeometry/doc/src/qtquick3d-examples-customgeometry.qdoc)  
68. Qt Quick 3D \- Custom Geometry Example, accessed on May 31, 2025, [https://doc.qt.io/qt-6/qtquick3d-customgeometry-example.html](https://doc.qt.io/qt-6/qtquick3d-customgeometry-example.html)  
69. How do I draw a simple line in Qt3D? \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/38067867/how-do-i-draw-a-simple-line-in-qt3d](https://stackoverflow.com/questions/38067867/how-do-i-draw-a-simple-line-in-qt3d)  
70. qt3d/qt3d/src/quick3d/line.cpp at master · mer-packages/qt3d \- GitHub, accessed on May 31, 2025, [https://github.com/mer-packages/qt3d/blob/master/qt3d/src/quick3d/line.cpp](https://github.com/mer-packages/qt3d/blob/master/qt3d/src/quick3d/line.cpp)  
71. Qt3d points and lines \- Qt Forum, accessed on May 31, 2025, [https://forum.qt.io/topic/76028/qt3d-points-and-lines](https://forum.qt.io/topic/76028/qt3d-points-and-lines)  
72. How do you draw a straight line between two points in a bitmap? \- Game Development Stack Exchange, accessed on May 31, 2025, [https://gamedev.stackexchange.com/questions/71299/how-do-you-draw-a-straight-line-between-two-points-in-a-bitmap](https://gamedev.stackexchange.com/questions/71299/how-do-you-draw-a-straight-line-between-two-points-in-a-bitmap)  
73. Calculate Angle Between Three 3D Points \- PerlMonks, accessed on May 31, 2025, [https://www.perlmonks.org/?node\_id=285244](https://www.perlmonks.org/?node_id=285244)  
74. Angle between 3 points? \- c++ \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/3486172/angle-between-3-points](https://stackoverflow.com/questions/3486172/angle-between-3-points)  
75. QText2DEntity \- how to print text in Qt3D? \- Qt Centre Forum, accessed on May 31, 2025, [https://www.qtcentre.org/threads/69647-QText2DEntity-how-to-print-text-in-Qt3D](https://www.qtcentre.org/threads/69647-QText2DEntity-how-to-print-text-in-Qt3D)  
76. Qt3D : How to display text on the 3D Window screen? \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/73193078/qt3d-how-to-display-text-on-the-3d-window-screen](https://stackoverflow.com/questions/73193078/qt3d-how-to-display-text-on-the-3d-window-screen)  
77. All Qt Examples | Qt | Qt Documentation (Pro) \- Felgo, accessed on May 31, 2025, [https://felgo.com/doc/qt/qtexamples/](https://felgo.com/doc/qt/qtexamples/)  
78. Qt3D 2.0 billboard transformation \- c++ \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/32357154/qt3d-2-0-billboard-transformation](https://stackoverflow.com/questions/32357154/qt3d-2-0-billboard-transformation)  
79. florianblume/qt3d-billboards: Billboard example based on https://github.com/wonder-sk/qt3d-experiments/tree/master/billboards. \- GitHub, accessed on May 31, 2025, [https://github.com/florianblume/qt3d-billboards](https://github.com/florianblume/qt3d-billboards)  
80. Qt 3D Basics \- Part 1 \- KDAB, accessed on May 31, 2025, [https://www.kdab.com/qt-3d-basics-part-1/](https://www.kdab.com/qt-3d-basics-part-1/)  
81. How to optimize point cloud rendering in Qt3D \- c++ \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/62792389/how-to-optimize-point-cloud-rendering-in-qt3d](https://stackoverflow.com/questions/62792389/how-to-optimize-point-cloud-rendering-in-qt3d)  
82. SimLOD: Simultaneous LOD Generation and Rendering for Point Clouds \- Research Unit of Computer Graphics | TU Wien, accessed on May 31, 2025, [https://www.cg.tuwien.ac.at/research/publications/2024/SCHUETZ-2024-SIMLOD/SCHUETZ-2024-SIMLOD-paper.pdf](https://www.cg.tuwien.ac.at/research/publications/2024/SCHUETZ-2024-SIMLOD/SCHUETZ-2024-SIMLOD-paper.pdf)  
83. m-schuetz/SimLOD: Simultaneous LOD Generation and ... \- GitHub, accessed on May 31, 2025, [https://github.com/m-schuetz/SimLOD](https://github.com/m-schuetz/SimLOD)  
84. Point Cloud Library \- Wikipedia, accessed on May 31, 2025, [https://en.wikipedia.org/wiki/Point\_Cloud\_Library](https://en.wikipedia.org/wiki/Point_Cloud_Library)  
85. A point cloud viewer implemented with Qt and PCL \- GitHub, accessed on May 31, 2025, [https://github.com/kuanyingchou/point-cloud-viewer](https://github.com/kuanyingchou/point-cloud-viewer)  
86. Qt 5.0: Camera and View Frustum, accessed on May 31, 2025, [https://qt.developpez.com/doc/5.0-snapshot/qt3d-camera-frustum/](https://qt.developpez.com/doc/5.0-snapshot/qt3d-camera-frustum/)  
87. Most basic working vbo example \- c++ \- Stack Overflow, accessed on May 31, 2025, [https://stackoverflow.com/questions/5091570/most-basic-working-vbo-example](https://stackoverflow.com/questions/5091570/most-basic-working-vbo-example)  
88. Draw a cube with vbo opengl \- Qt Forum, accessed on May 31, 2025, [https://forum.qt.io/topic/57774/draw-a-cube-with-vbo-opengl](https://forum.qt.io/topic/57774/draw-a-cube-with-vbo-opengl)  
89. OpenGL: Open Graphics Library \- a community for discussion, help and news. \- Reddit, accessed on May 31, 2025, [https://www.reddit.com/r/opengl/best/?after=dDNfMWp2eHNucg%3D%3D\&sort=best\&t=hour\&feedViewType=cardView](https://www.reddit.com/r/opengl/best/?after=dDNfMWp2eHNucg%3D%3D&sort=best&t=hour&feedViewType=cardView)  
90. Rendering performance when using CUDA interop worsens by 500% : r/opengl \- Reddit, accessed on May 31, 2025, [https://www.reddit.com/r/opengl/comments/1j8ner2/rendering\_performance\_when\_using\_cuda\_interop/](https://www.reddit.com/r/opengl/comments/1j8ner2/rendering_performance_when_using_cuda_interop/)  
91. Problems with Qt/OpenGL linked with CUDA library \- Qt Forum, accessed on May 31, 2025, [https://forum.qt.io/topic/51595/problems-with-qt-opengl-linked-with-cuda-library](https://forum.qt.io/topic/51595/problems-with-qt-opengl-linked-with-cuda-library)  
92. diegomazala/QtCudaOpenGL: Example of project using Qt, Cuda and Opengl \- GitHub, accessed on May 31, 2025, [https://github.com/diegomazala/QtCudaOpenGL](https://github.com/diegomazala/QtCudaOpenGL)  
93. Overview of Qt3D 2.0 \- Part 2 \- KDAB, accessed on May 31, 2025, [https://www.kdab.com/overview-qt3d-2-0-part-2/](https://www.kdab.com/overview-qt3d-2-0-part-2/)  
94. Qt3DWindow \- Qt for Python \- Qt Documentation, accessed on May 31, 2025, [https://doc.qt.io/qtforpython-6.5/PySide6/Qt3DExtras/Qt3DWindow.html](https://doc.qt.io/qtforpython-6.5/PySide6/Qt3DExtras/Qt3DWindow.html)  
95. Embed an application inside a Qt Window \[SOLVED\] \- Qt Forum, accessed on May 31, 2025, [https://forum.qt.io/topic/44091/embed-an-application-inside-a-qt-window-solved](https://forum.qt.io/topic/44091/embed-an-application-inside-a-qt-window-solved)  
96. How can i measure the distance between each point of my 3D points-cloud and the mean plan? \- MATLAB Answers \- MathWorks, accessed on May 31, 2025, [https://www.mathworks.com/matlabcentral/answers/182812-how-can-i-measure-the-distance-between-each-point-of-my-3d-points-cloud-and-the-mean-plan](https://www.mathworks.com/matlabcentral/answers/182812-how-can-i-measure-the-distance-between-each-point-of-my-3d-points-cloud-and-the-mean-plan)