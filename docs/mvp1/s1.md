Sprint 1 Backlog: 3D Point Cloud Visualization

Sprint Goal: To establish the foundational 3D visualization capabilities for the point cloud registration tool, enabling users to load, view, and interact with large point cloud datasets in a 3D environment with high performance.
Introduction

This document outlines the detailed backlog for Sprint 1, which is dedicated to implementing the core 3D point cloud visualization features. The existing application has a solid backend for project management and data processing but currently lacks a graphical user interface for viewing and interacting with the point cloud data. This sprint is critical as it will bridge that gap by integrating a performant OpenGL-based viewer into the existing Qt application framework. The primary focus is on efficient rendering of large-scale data, the implementation of smooth and intuitive camera controls, and establishing a robust architectural foundation for all future registration and analysis tasks that depend on visual feedback.
User Stories

    User Story 1: Basic 3D Point Cloud Rendering

        Description: As a surveyor, I need to see the point cloud I've loaded accurately displayed in a 3D view. This is essential for me to visually inspect the captured data for completeness, identify potential coverage gaps, and get a general sense of the environment before beginning the registration process. A clear and correct visual representation is the first step in quality assurance.

        Actions to Undertake:

            Integrate OpenGL Widget: Embed a QOpenGLWidget into the main window's central project view area. This widget will be the designated canvas for all 3D rendering operations and must be correctly initialized within the Qt layout.

            Develop Rendering Engine: Create a core OpenGLRenderer class. This class will encapsulate the rendering logic, including managing shader program lifecycle (compilation, linking, binding), handling Vertex Buffer Objects (VBOs) and Vertex Array Objects (VAOs), and executing the main rendering loop via paintGL().

            Create Point Cloud Shaders: Write the initial GLSL vertex (pointcloud.vert) and fragment (pointcloud.frag) shaders. The vertex shader will be responsible for transforming vertex positions using a Model-View-Projection (MVP) matrix. The fragment shader will output a uniform color, making all points appear consistent for this initial story.

            Implement Data Loading: Create a robust data pipeline where the PointCloudViewerWidget, implementing the IPointCloudViewer interface, receives point data (as a std::vector<float>) from the MainPresenter. This data will then be uploaded to a VBO on the GPU for efficient rendering.

            Establish Rendering Pipeline: Connect the "Open File" UI action to the complete data loading and rendering pipeline. This ensures that once a file is successfully parsed by the backend, the resulting point data is immediately passed to the viewer, which then triggers a render update to display the new cloud.

        References between Files:

            MainWindow will instantiate and manage the layout of the PointCloudViewerWidget.

            MainPresenter will orchestrate the data flow, calling IPointCloudViewer->loadPointCloud() to push data from the file parsers into the PointCloudViewerWidget.

            PointCloudViewerWidget will delegate rendering calls to its OpenGLRenderer instance.

            OpenGLRenderer is responsible for reading, compiling, and linking the pointcloud.vert and pointcloud.frag shader files.

        Acceptance Criteria:

            A point cloud of at least 1 million points can be loaded and displayed without crashing.

            The rendered point cloud is clearly visible within the dedicated 3D widget.

            The application maintains a responsive UI (>30 FPS) while rendering the static point cloud.

            The viewer correctly clears any previous data and displays the new point cloud when a different file is opened.

            Upon loading, the initial camera view is automatically framed to ensure the entire point cloud is visible without requiring manual user adjustment.

        Testing Plan:

            Manual Test: Load various E57 and LAS files (small, medium, large) to verify they appear correctly.

            Unit Test: Write a specific test case for PointCloudViewerWidget::loadPointCloud using a predefined std::vector<float> to confirm that the VBO is populated with the correct data and size.

            Performance Test: Load a dataset with over 10 million points and use an internal profiler to confirm the rendering frame rate remains consistently above 30 FPS.

            Regression Test: Ensure that opening a new file correctly clears all data associated with the previously opened file.

    User Story 2: Interactive Camera Controls

        Description: As a user, I need to freely navigate the 3D scene using my mouse. This includes rotating my viewpoint (orbit), moving my viewpoint parallel to the screen (pan), and moving closer or further away (zoom), so I can thoroughly examine specific areas of the point cloud, check for details, and assess the spatial relationship between different parts of the scan.

        Actions to Undertake:

            Implement Camera Class: Develop a dedicated CameraController class to encapsulate all camera logic. This class will manage the view and projection matrices and contain the mathematical logic for orbit (using spherical coordinates or quaternions), pan, and zoom operations.

            Handle Mouse Input: In PointCloudViewerWidget, override and implement the mousePressEvent, mouseMoveEvent, and wheelEvent methods to accurately capture the user's mouse actions.

            Connect Input to Camera: Translate the captured mouse deltas and wheel scrolls into commands for the CameraController. A left-click-and-drag will trigger an orbit operation, a right-click-and-drag will trigger a pan, and the scroll wheel will adjust the zoom level.

            Update View Matrix: After each camera manipulation, the CameraController will recalculate the view matrix. This updated matrix must be passed to the OpenGLRenderer as a shader uniform before each frame is rendered.

            Implement "Fit to View": Create a public method, fitToView(), that resets the camera's position and orientation to a default state, ensuring the entire point cloud's bounding box is framed within the viewport. This action will be connected to a toolbar button.

        References between Files:

            PointCloudViewerWidget will contain and manage a CameraController instance, forwarding mouse events to it.

            CameraController will expose a method like getViewMatrix() that OpenGLRenderer will call to get the updated camera transformation for rendering.

        Acceptance Criteria:

            The user can smoothly orbit the point cloud around its calculated center by holding and dragging the left mouse button.

            The user can pan the view (move it horizontally and vertically) by holding and dragging the right mouse button.

            The user can zoom in and out smoothly using the mouse scroll wheel.

            All camera movements feel fluid and intuitive, without any stuttering or unexpected jumps.

            A UI action (e.g., a toolbar button) exists to reset the camera view, which correctly frames the entire point cloud.

        Testing Plan:

            Manual Test: Systematically perform all camera manipulations on various parts of a loaded point cloud. Ensure the view responds correctly and predictably.

            Usability Test: Ask a new user to navigate to a specific feature within the point cloud. Observe their interactions to determine if the controls are intuitive and discoverable.

            Automated UI Test: Write a test script that simulates a sequence of mouse events (e.g., a drag from point A to B) and asserts that the camera's final view matrix corresponds to the expected transformation.

    User Story 3: Level of Detail (LOD) System for Performance

        Description: As a developer, I need to implement a dynamic Level of Detail (LOD) system. This is crucial for maintaining application performance and ensuring a responsive user experience when rendering very large point clouds (e.g., 50M+ points), which would otherwise overwhelm the GPU and cause the application to freeze.

        Actions to Undertake:

            Extend Octree: Enhance the existing Octree data structure. Each node in the tree will need to store a representative subset of its points or pre-calculated aggregate data (like a centroid) to be used for lower-detail rendering.

            Implement LOD Manager: Create a dedicated LODManager class. This manager will be responsible for traversing the Octree each frame, using camera information to make decisions about which nodes to render.

            Distance-Based Culling: Implement logic within the LODManager to calculate the distance from the camera to each octree node's bounding box. Based on this distance, the manager will decide whether to render the node's points at high detail, low detail, or not at all.

            Frustum Culling: Before performing any distance checks, the LODManager will first test if an octree node's bounding box intersects with the camera's view frustum. If a node is completely outside the view, it and all its children will be culled, saving significant processing time.

            Dynamic Point Selection: The LODManager will compile a final, dynamic list of points to be rendered for the current frame. This list will be provided to the OpenGLRenderer, which will then upload this smaller dataset to the VBO for rendering.

        References between Files:

            LODManager will hold a reference to the Octree to traverse its structure.

            LODManager will require access to the CameraController to get the current camera position and view frustum.

            OpenGLRenderer will be modified to accept a dynamic list of points from the LODManager for each frame, rather than rendering a static VBO.

        Acceptance Criteria:

            The application can successfully load and navigate a 50 million point dataset, maintaining an interactive frame rate (consistently >30 FPS).

            When the user zooms out, the density of the rendered point cloud visibly decreases, demonstrating that fewer points are being drawn.

            The transition between different levels of detail is seamless, with no noticeable "popping" of nodes or jarring visual artifacts.

            When zoomed in on a small section of the point cloud, the total number of points rendered per frame is a small fraction of the total dataset size, as verified by a performance counter.

        Testing Plan:

            Performance Test: Load a very large dataset (50M+ points). While navigating (zooming, panning, orbiting), continuously monitor the FPS and the count of rendered points per frame to ensure they meet performance targets.

            Visual Test: On a large, dense point cloud, zoom out and visually confirm that distant parts of the cloud appear sparser than nearby parts. Check that no large, visible holes appear in the data due to incorrect culling.

            Unit Test: Test the LODManager's selection logic in isolation. Provide it with a mock camera and octree, and assert that it returns the expected number of points and nodes for various camera positions and distances.

List of Files being Created

    File 1: src/rendering/OpenGLRenderer.h/.cpp

        Purpose: This class will encapsulate the core OpenGL rendering logic, abstracting away the low-level API calls from the main viewer widget. It is responsible for managing the lifecycle of OpenGL resources.

        Contents: OpenGLRenderer class with methods to initialize the OpenGL state, compile and link GLSL shader programs, create and manage VBOs/VAOs, and execute the rendering commands for a given frame.

        Relationships: This class will be instantiated and owned by PointCloudViewerWidget. It will load and use shader code from pointcloud.vert and pointcloud.frag.

    File 2: src/camera/CameraController.h/.cpp

        Purpose: To centralize all camera-related logic, providing a clean interface for manipulating the 3D view. This separation of concerns simplifies the viewer widget's responsibilities.

        Contents: CameraController class containing methods to perform orbit, pan, and zoom operations. It will internally manage the camera's position, target, up-vector, and field of view to generate the final view and projection matrices.

        Relationships: This class will be a member of PointCloudViewerWidget and will be updated by its mouse event handlers.

    File 3: src/rendering/LODManager.h/.cpp

        Purpose: To implement the Level of Detail (LOD) logic required for rendering large datasets performantly. It will act as the decision-maker for what gets rendered each frame.

        Contents: LODManager class that will traverse the Octree data structure. It will contain methods for frustum culling and distance-based detail selection.

        Relationships: It uses data from the Octree and CameraController to determine a list of visible points, which it then provides to the OpenGLRenderer.

    File 4: shaders/pointcloud.vert

        Purpose: The vertex shader is responsible for processing each point's vertex data. Its primary role is to calculate the final screen position of each point.

        Contents: GLSL code that takes a vertex position and a Model-View-Projection (MVP) matrix as input and outputs the transformed gl_Position.

        Relationships: This file is loaded, compiled, and used by the OpenGLRenderer.

    File 5: shaders/pointcloud.frag

        Purpose: The fragment shader is responsible for determining the final color of each pixel that makes up a rendered point.

        Contents: GLSL code that receives data from the vertex shader and outputs a final color (fragColor). Initially, this will be a simple uniform color.

        Relationships: This file is loaded, compiled, and used by the OpenGLRenderer.

    File 6: src/ui/ViewerToolbar.h/.cpp

        Purpose: To provide a dedicated UI area for viewer-specific actions, such as camera controls, making them easily accessible to the user.

        Contents: A QToolBar or a custom QWidget containing QPushButtons for actions like "Fit to View" and selecting standard camera presets (Top, Front, Side).

        Relationships: This widget will be integrated into the MainWindow's layout and will emit signals connected to slots in PointCloudViewerWidget.

    File 7: tests/test_opengl_renderer.cpp

        Purpose: To ensure the reliability and correctness of the core rendering engine through automated testing.

        Contents: GTest cases that verify the OpenGLRenderer can successfully compile its shaders, create OpenGL buffers, and that its rendering logic is sound (e.g., by checking for OpenGL errors after render calls).

        Relationships: This test file will directly include and test the OpenGLRenderer class.

    File 8: tests/test_camera_controller.cpp

        Purpose: To provide automated verification of the camera's movement and matrix generation logic.

        Contents: GTest cases that simulate user input and assert that the CameraController produces the correct view matrix for different orbit, pan, and zoom operations.

        Relationships: This test file will directly include and test the CameraController class.

Acceptance Criteria (Sprint-Level)

    Functional:

        [ ] The application can successfully load and display point clouds from both E57 and LAS files in the integrated 3D view without errors.

        [ ] Users have a full suite of interactive camera controls, including orbit, pan, and zoom, allowing for complete and fluid navigation of the 3D scene.

        [ ] The new viewer is fully integrated with the existing application, receiving data correctly from the MainPresenter after file parsing is complete.

    Performance:

        [ ] The viewer can render a 10 million point dataset at a sustained minimum of 30 FPS on the target hardware configuration during navigation.

        [ ] The LOD system demonstrates a clear and measurable performance improvement (e.g., a 50% increase in FPS) on datasets larger than 20 million points compared to rendering all points.

        [ ] All camera movements and animations must maintain a fluid 60 FPS update rate to ensure a smooth user experience.

    Quality:

        [ ] The 3D rendering output is visually correct and free of common graphics artifacts such as z-fighting, flickering, or incorrect point colors.

        [ ] The new rendering, camera, and LOD components are thoroughly documented with code comments and have a unit test coverage exceeding 80% to ensure maintainability.

        [ ] All new UI elements, such as the ViewerToolbar, are styled to be visually consistent with the existing application's theme and design language.

Testing Plan

    Test Case 1: Load and Render Verification

        Test Data: A standard, known E57 file and a known LAS file to ensure both formats are supported.

        Expected Result: The point cloud is rendered completely and accurately in the 3D viewer. The initial camera view automatically adjusts to frame the entire point cloud. No points should be visibly missing or misplaced.

        Testing Tool: Manual testing within the application.

    Test Case 2: Camera Control Functionality

        Test Data: Any loaded point cloud dataset.

        Expected Result: Orbit, pan, and zoom controls function smoothly and predictably. The "Fit to View" button correctly resets the camera to the default view, making the entire point cloud visible.

        Testing Tool: Manual user interaction testing.

    Test Case 3: LOD Performance Benchmark

        Test Data: A very large point cloud file (at least 50 million points) to properly stress the LOD system.

        Expected Result: The application maintains a frame rate above 30 FPS throughout navigation. The number of rendered points (displayed via a debug overlay) should dynamically decrease as the user zooms out and increase as they zoom in.

        Testing Tool: Use the internal performance profiler to monitor FPS and rendered point count in real-time. Visual inspection to confirm density changes.

    Test Case 4: Shader Compilation Test

        Test Data: N/A.

        Expected Result: Both the vertex and fragment shaders compile and link without any errors upon application startup. The OpenGLRenderer reports successful shader program creation.

        Testing Tool: Automated unit test as part of the test_opengl_renderer.cpp suite, which will fail if shaders do not compile.

Assumptions and Dependencies

    Assumptions:

        The existing IPointCloudViewer interface is sufficiently comprehensive for the MainPresenter to control the new PointCloudViewerWidget without requiring interface changes.

        The target development and deployment machines have a working OpenGL 3.3+ compatible graphics driver installed.

        The current Octree implementation in the codebase is robust and can be extended to store per-node data required for the LOD system.

    Dependencies:

        Qt 6: The application's UI and windowing system rely on the Qt framework, specifically the QtWidgets, QtGui, and QtOpenGL modules.

        OpenGL: The rendering engine will be built directly on top of the OpenGL API, requiring at least version 3.3 core profile support.

        Existing Codebase: The new viewer must integrate cleanly with the existing MainPresenter for data flow, ProjectManager for context, and the file parsing logic for receiving point data.

Non-Functional Requirements

    Performance: The viewer must be designed to handle large datasets efficiently, aiming to support up to 100 million points with the LOD system enabled, without causing the UI to become unresponsive.

    Usability: The camera controls must be highly intuitive, adhering to established conventions found in other 3D modeling and CAD software to minimize the learning curve for new users.

    Maintainability: The rendering code must be structured in a modular and decoupled manner (e.g., separating renderer, camera, and LOD logic). This is essential for simplifying future maintenance and the addition of new features like different rendering modes or lighting models.

    Compatibility: The OpenGL-based viewer must be implemented using cross-platform code that functions correctly on all target operating systems (Windows, Linux, and macOS) supported by the overall application.

Conclusion

Upon the successful completion of Sprint 1, the application will be equipped with a functional, interactive, and performant 3D point cloud viewer. This delivers immediate and significant value to the user by enabling, for the first time, the visual inspection and exploration of their data. More importantly, it establishes the critical visual foundation upon which all subsequent registration features—from manual target selection in the 3D view to the visualization of final alignment results—will be built. The delivery of this sprint is a cornerstone achievement for the MVP and unblocks a significant portion of the future development roadmap.